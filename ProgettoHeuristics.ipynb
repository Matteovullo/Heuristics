{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7eea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, Tuple, List, Optional, Set\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class MaxFlowTabuSearch:\n",
    "    \"\"\"\n",
    "    Implementazione Tabu Search per il problema del flusso massimo con visualizzazione migliorata.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph: Dict[Tuple[int, int], float], source: int, sink: int,\n",
    "                 tabu_tenure: int = 20, max_iterations: int = 20000):\n",
    "        self.source = source\n",
    "        self.sink = sink\n",
    "        self.graph = graph\n",
    "\n",
    "        # Mappatura nodi\n",
    "        self.node_map, self.reverse_node_map = self._create_node_mapping()\n",
    "        self.source = self.node_map[source]\n",
    "        self.sink = self.node_map[sink]\n",
    "\n",
    "        # Build mapped graph\n",
    "        self.graph_mapped = {}\n",
    "        for (u, v), cap in graph.items():\n",
    "            self.graph_mapped[(self.node_map[u], self.node_map[v])] = cap\n",
    "\n",
    "        # Parameters\n",
    "        self.tabu_tenure = tabu_tenure\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "        # Data structures\n",
    "        self.edges = list(self.graph_mapped.keys())\n",
    "        self.capacities = np.array([self.graph_mapped[e] for e in self.edges], dtype=np.float32)\n",
    "        self.edge_to_idx = {(u, v): i for i, (u, v) in enumerate(self.edges)}\n",
    "\n",
    "        # Flow arrays\n",
    "        self.current_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        self.best_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        self.temp_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        self.initial_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "\n",
    "        # Statistics\n",
    "        self.best_value = 0.0\n",
    "        self.convergence_history = []\n",
    "        self.convergence_iterations = []  # Track exact iteration numbers\n",
    "        self.evaluations = 0\n",
    "        self.best_iteration = 0\n",
    "        self.tabu_list = {}\n",
    "        self.start_time = time.time()\n",
    "\n",
    "        # Build adjacency lists\n",
    "        self._build_adjacency_lists()\n",
    "\n",
    "        # Calculate capacities\n",
    "        self.source_out_capacity = sum(cap for (u, v), cap in self.graph_mapped.items() if u == self.source)\n",
    "        self.sink_in_capacity = sum(cap for (u, v), cap in self.graph_mapped.items() if v == self.sink)\n",
    "\n",
    "        # Calculate optimal max flow\n",
    "        self.optimal_max_flow_value = self._run_edmonds_karp()\n",
    "        print(f\"Optimal max flow (EK): {self.optimal_max_flow_value:.2f}\")\n",
    "\n",
    "        # Initialize with intelligent solution\n",
    "        self._init_with_partial_edmonds_karp()\n",
    "\n",
    "    def _create_node_mapping(self) -> Tuple[Dict[int, int], Dict[int, int]]:\n",
    "        \"\"\"Create mapping from original node IDs to consecutive indices.\"\"\"\n",
    "        all_nodes = set()\n",
    "        for u, v in self.graph.keys():\n",
    "            all_nodes.add(u)\n",
    "            all_nodes.add(v)\n",
    "\n",
    "        node_list = []\n",
    "        if self.source in all_nodes:\n",
    "            node_list.append(self.source)\n",
    "        if self.sink in all_nodes and self.sink != self.source:\n",
    "            node_list.append(self.sink)\n",
    "\n",
    "        for node in sorted(list(all_nodes)):\n",
    "            if node not in node_list:\n",
    "                node_list.append(node)\n",
    "\n",
    "        node_map = {node: i for i, node in enumerate(node_list)}\n",
    "        reverse_map = {i: node for i, node in enumerate(node_list)}\n",
    "\n",
    "        return node_map, reverse_map\n",
    "\n",
    "    def _build_adjacency_lists(self) -> None:\n",
    "        \"\"\"Build adjacency lists for efficient graph navigation.\"\"\"\n",
    "        self.outgoing = defaultdict(list)\n",
    "        self.incoming = defaultdict(list)\n",
    "\n",
    "        for i, (u, v) in enumerate(self.edges):\n",
    "            self.outgoing[u].append((i, v))\n",
    "            self.incoming[v].append((i, u))\n",
    "\n",
    "    def _run_edmonds_karp(self) -> float:\n",
    "        \"\"\"Edmonds-Karp implementation for maximum flow (reference solution).\"\"\"\n",
    "        flow = 0.0\n",
    "        residual = defaultdict(dict)\n",
    "\n",
    "        # Initialize residual network\n",
    "        for (u, v), cap in self.graph_mapped.items():\n",
    "            residual[u][v] = cap\n",
    "            residual[v][u] = 0.0\n",
    "\n",
    "        while True:\n",
    "            # BFS to find augmenting path\n",
    "            parent = {}\n",
    "            visited = set()\n",
    "            queue = deque([self.source])\n",
    "            visited.add(self.source)\n",
    "            found = False\n",
    "\n",
    "            while queue and not found:\n",
    "                u = queue.popleft()\n",
    "                for v, cap in residual[u].items():\n",
    "                    if cap > 1e-6 and v not in visited:\n",
    "                        parent[v] = u\n",
    "                        visited.add(v)\n",
    "                        if v == self.sink:\n",
    "                            found = True\n",
    "                            break\n",
    "                        queue.append(v)\n",
    "\n",
    "            if not found:\n",
    "                break\n",
    "\n",
    "            # Find minimum residual capacity\n",
    "            path_flow = float('inf')\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                path_flow = min(path_flow, residual[u][v])\n",
    "                v = u\n",
    "\n",
    "            # Update flows and residual capacities\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                residual[u][v] -= path_flow\n",
    "                residual[v][u] += path_flow\n",
    "                v = u\n",
    "\n",
    "            flow += path_flow\n",
    "\n",
    "        return flow\n",
    "\n",
    "    def _init_with_partial_edmonds_karp(self) -> None:\n",
    "        \"\"\"Initialize with a partial solution based on Edmonds-Karp.\"\"\"\n",
    "        #print(\"Generating intelligent initial solution...\")\n",
    "        optimal_flow = self._run_internal_edmonds_karp()\n",
    "        factor = random.uniform(0.7, 0.95)  # Changed from original\n",
    "        self.current_flow = optimal_flow * factor\n",
    "        np.copyto(self.initial_flow, self.current_flow)\n",
    "        self.best_value = self._calculate_flow_value(self.current_flow)\n",
    "        np.copyto(self.best_flow, self.current_flow)\n",
    "        print(f\"Initial solution: {self.best_value:.2f} (vs optimal {self.optimal_max_flow_value:.2f})\")\n",
    "\n",
    "        # Record initial state\n",
    "        self.convergence_history.append(self.best_value)\n",
    "        self.convergence_iterations.append(0)\n",
    "\n",
    "    def _run_internal_edmonds_karp(self) -> np.array:\n",
    "        \"\"\"Run Edmonds-Karp internally and return flow assignment.\"\"\"\n",
    "        flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        residual = {}\n",
    "\n",
    "        # Initialize residual network\n",
    "        for idx, (u, v) in enumerate(self.edges):\n",
    "            residual[(u, v)] = self.capacities[idx]\n",
    "            residual[(v, u)] = 0.0\n",
    "\n",
    "        while True:\n",
    "            # BFS to find augmenting path\n",
    "            queue = deque([self.source])\n",
    "            parent = {}\n",
    "            visited = {self.source}\n",
    "            found_path = False\n",
    "\n",
    "            while queue and not found_path:\n",
    "                u = queue.popleft()\n",
    "                for (x, y), cap in residual.items():\n",
    "                    if x == u and cap > 1e-6 and y not in visited:\n",
    "                        visited.add(y)\n",
    "                        parent[y] = (u, (x, y))\n",
    "                        if y == self.sink:\n",
    "                            found_path = True\n",
    "                            break\n",
    "                        queue.append(y)\n",
    "\n",
    "            if not found_path:\n",
    "                break\n",
    "\n",
    "            # Find minimum residual capacity\n",
    "            path_flow = float('inf')\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u, edge = parent[v]\n",
    "                path_flow = min(path_flow, residual[edge])\n",
    "                v = u\n",
    "\n",
    "            # Update flow and residual network\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u, edge = parent[v]\n",
    "                idx = self.edge_to_idx.get(edge, -1)\n",
    "                if idx >= 0:\n",
    "                    flow[idx] += path_flow\n",
    "                    residual[edge] -= path_flow\n",
    "                    rev_edge = (edge[1], edge[0])\n",
    "                    residual[rev_edge] += path_flow\n",
    "                v = u\n",
    "\n",
    "        return flow\n",
    "\n",
    "    def _calculate_flow_value(self, flow: np.array) -> float:\n",
    "        \"\"\"Calculate total flow value exiting the source.\"\"\"\n",
    "        self.evaluations += 1\n",
    "        return sum(flow[idx] for idx, (u, v) in enumerate(self.edges) if u == self.source)\n",
    "\n",
    "    def _is_feasible(self, flow: np.array) -> bool:\n",
    "        \"\"\"Check if a flow assignment is feasible.\"\"\"\n",
    "        # Capacity constraints\n",
    "        if np.any(flow < -1e-7) or np.any(flow > self.capacities + 1e-7):\n",
    "            return False\n",
    "\n",
    "        # Flow conservation\n",
    "        inflow = defaultdict(float)\n",
    "        outflow = defaultdict(float)\n",
    "\n",
    "        for idx, (u, v) in enumerate(self.edges):\n",
    "            inflow[v] += flow[idx]\n",
    "            outflow[u] += flow[idx]\n",
    "\n",
    "        for node in set(inflow.keys()).union(outflow.keys()):\n",
    "            if node == self.source or node == self.sink:\n",
    "                continue\n",
    "            if abs(inflow[node] - outflow[node]) > 1e-5:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _check_optimality_condition(self, flow_value: float) -> bool:\n",
    "        \"\"\"Check if flow equals sum of source outgoing or sink incoming capacities.\"\"\"\n",
    "        return (abs(flow_value - self.source_out_capacity) < 1e-6 or\n",
    "                abs(flow_value - self.sink_in_capacity) < 1e-6)\n",
    "\n",
    "    def _find_augmenting_path(self, flow: np.array) -> Optional[List[Tuple[int, bool]]]:\n",
    "        \"\"\"Find an augmenting path in the residual network.\"\"\"\n",
    "        visited = set()\n",
    "        parent = {}\n",
    "        queue = deque([self.source])\n",
    "\n",
    "        while queue:\n",
    "            node = queue.popleft()\n",
    "\n",
    "            if node == self.sink:\n",
    "                # Reconstruct path with direction information\n",
    "                path_info = []\n",
    "                current = self.sink\n",
    "                while current != self.source:\n",
    "                    u, (edge_idx, is_forward) = parent[current]\n",
    "                    path_info.append((edge_idx, is_forward))\n",
    "                    current = u\n",
    "                return list(reversed(path_info))\n",
    "\n",
    "            if node in visited:\n",
    "                continue\n",
    "            visited.add(node)\n",
    "\n",
    "            # Forward edges\n",
    "            for edge_idx, target in self.outgoing[node]:\n",
    "                residual = self.capacities[edge_idx] - flow[edge_idx]\n",
    "                if residual > 1e-6 and target not in visited:\n",
    "                    parent[target] = (node, (edge_idx, True))\n",
    "                    queue.append(target)\n",
    "\n",
    "            # Backward edges\n",
    "            for edge_idx, source_node in self.incoming[node]:\n",
    "                if flow[edge_idx] > 1e-6 and source_node not in visited:\n",
    "                    parent[source_node] = (node, (edge_idx, False))\n",
    "                    queue.append(source_node)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _apply_path_flow(self, current_flow: np.array,\n",
    "                        path_info: List[Tuple[int, bool]], amount: float) -> np.array:\n",
    "        \"\"\"Apply flow along an augmenting path.\"\"\"\n",
    "        np.copyto(self.temp_flow, current_flow)\n",
    "        for edge_idx, is_forward in path_info:\n",
    "            if is_forward:\n",
    "                self.temp_flow[edge_idx] += amount\n",
    "            else:\n",
    "                self.temp_flow[edge_idx] -= amount\n",
    "        return self.temp_flow.copy()\n",
    "\n",
    "    def _get_neighborhood_moves(self, current_flow: np.array, iteration: int) -> List[Tuple]:\n",
    "        \"\"\"Generate neighborhood moves for the current solution.\"\"\"\n",
    "        moves = []\n",
    "\n",
    "        # Edge-based moves (sample more edges for larger graphs)\n",
    "        sample_size = min(len(self.edges), max(300, len(self.edges) // 10))\n",
    "        sampled_edges = random.sample(range(len(self.edges)), sample_size)\n",
    "\n",
    "        for edge_idx in sampled_edges:\n",
    "            current_f = current_flow[edge_idx]\n",
    "            capacity = self.capacities[edge_idx]\n",
    "\n",
    "            # Increment move\n",
    "            if current_f < capacity - 1e-6:\n",
    "                step_size = capacity * random.uniform(0.05, 0.25)\n",
    "                step = min(capacity - current_f, step_size)\n",
    "                if step > 1e-6:\n",
    "                    np.copyto(self.temp_flow, current_flow)\n",
    "                    self.temp_flow[edge_idx] += step\n",
    "                    is_tabu = edge_idx in self.tabu_list and self.tabu_list[edge_idx] > iteration\n",
    "                    moves.append((self.temp_flow.copy(), edge_idx, step, is_tabu))\n",
    "\n",
    "            # Decrement move\n",
    "            if current_f > 1e-6:\n",
    "                step_size = capacity * random.uniform(0.05, 0.25)\n",
    "                step = min(current_f, step_size)\n",
    "                if step > 1e-6:\n",
    "                    np.copyto(self.temp_flow, current_flow)\n",
    "                    self.temp_flow[edge_idx] -= step\n",
    "                    is_tabu = edge_idx in self.tabu_list and self.tabu_list[edge_idx] > iteration\n",
    "                    moves.append((self.temp_flow.copy(), edge_idx, -step, is_tabu))\n",
    "\n",
    "        # Augmenting path move\n",
    "        path_info = self._find_augmenting_path(current_flow)\n",
    "        if path_info:\n",
    "            min_residual = float('inf')\n",
    "            for edge_idx, is_forward in path_info:\n",
    "                if is_forward:\n",
    "                    min_residual = min(min_residual,\n",
    "                                     self.capacities[edge_idx] - current_flow[edge_idx])\n",
    "                else:\n",
    "                    min_residual = min(min_residual, current_flow[edge_idx])\n",
    "\n",
    "            if min_residual > 1e-6:\n",
    "                amount = min(min_residual, min_residual * random.uniform(0.1, 0.9))\n",
    "                new_flow = self._apply_path_flow(current_flow, path_info, amount)\n",
    "                path_edges = tuple([info[0] for info in path_info])\n",
    "                moves.append((new_flow, path_edges, amount, False))\n",
    "\n",
    "        # Edge exchange moves\n",
    "        if len(sampled_edges) >= 2:\n",
    "            for _ in range(min(20, len(sampled_edges) // 2)):\n",
    "                edge1, edge2 = random.sample(sampled_edges, 2)\n",
    "                if (current_flow[edge1] > 1e-6 and\n",
    "                    current_flow[edge2] < self.capacities[edge2] - 1e-6):\n",
    "                    max_transfer = min(current_flow[edge1],\n",
    "                                     self.capacities[edge2] - current_flow[edge2])\n",
    "                    transfer = max_transfer * random.uniform(0.1, 0.5)\n",
    "                    if transfer > 1e-6:\n",
    "                        np.copyto(self.temp_flow, current_flow)\n",
    "                        self.temp_flow[edge1] -= transfer\n",
    "                        self.temp_flow[edge2] += transfer\n",
    "                        moves.append((self.temp_flow.copy(), (edge1, edge2), transfer, False))\n",
    "\n",
    "        return moves\n",
    "\n",
    "    def _diversify_solution(self, current_flow: np.array) -> np.array:\n",
    "        \"\"\"Diversify the current solution when stagnation is detected.\"\"\"\n",
    "        print(\"Applying diversification...\")\n",
    "        reset_factor = random.uniform(0.5, 0.9)  # More aggressive reset\n",
    "        noise_factor = random.uniform(0.2, 0.4)  # More noise\n",
    "\n",
    "        new_flow = current_flow * (1 - reset_factor) + self.initial_flow * reset_factor\n",
    "\n",
    "        num_edges_to_perturb = min(len(self.edges) // 5, 50)\n",
    "        edges_to_perturb = random.sample(range(len(self.edges)), num_edges_to_perturb)\n",
    "\n",
    "        for edge_idx in edges_to_perturb:\n",
    "            capacity = self.capacities[edge_idx]\n",
    "            if capacity > 0:\n",
    "                noise = random.uniform(-noise_factor, noise_factor) * capacity\n",
    "                new_flow[edge_idx] = max(0, min(capacity, new_flow[edge_idx] + noise))\n",
    "\n",
    "        return new_flow\n",
    "\n",
    "    def _adaptive_parameters(self, iteration: int, stagnation_counter: int) -> bool:\n",
    "        \"\"\"Adapt algorithm parameters during the search.\"\"\"\n",
    "        if stagnation_counter > 100:  # More sensitive to stagnation\n",
    "            self.tabu_tenure = min(int(self.tabu_tenure * 1.25), 150)  # Larger changes\n",
    "        elif stagnation_counter < 50:\n",
    "            self.tabu_tenure = max(int(self.tabu_tenure * 0.9), 10)\n",
    "\n",
    "        if iteration % 2000 == 0 and iteration > 0 and stagnation_counter > 300:\n",
    "            self.current_flow = self._diversify_solution(self.current_flow)\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def plot_convergence(self, filename: Optional[str] = None, title_suffix: str = \"\") -> None:\n",
    "        \"\"\"Generate and optionally save convergence plot with accurate iteration tracking.\"\"\"\n",
    "        plt.figure(figsize=(12, 7))\n",
    "\n",
    "        # Use exact iteration points\n",
    "        iterations = np.array(self.convergence_iterations)\n",
    "        values = np.array(self.convergence_history)\n",
    "\n",
    "        # Create main plot\n",
    "        plt.plot(iterations, values, 'b-', linewidth=2, label='Best Flow Value')\n",
    "\n",
    "        # Optimal value line\n",
    "        plt.axhline(y=self.optimal_max_flow_value, color='r', linestyle='--',\n",
    "                   linewidth=1.5, label=f'Optimal (EK): {self.optimal_max_flow_value:.2f}')\n",
    "\n",
    "        # Mark best solution point\n",
    "        plt.scatter([self.best_iteration], [self.best_value], color='g',\n",
    "                   s=100, zorder=5, label=f'Best: {self.best_value:.2f} at {self.best_iteration}')\n",
    "\n",
    "        # Enhanced formatting\n",
    "        plt.title(f'Tabu Search Convergence {title_suffix}\\n'\n",
    "                 f'Nodes: {len(self.node_map)}, Edges: {len(self.edges)}', pad=20)\n",
    "        plt.xlabel('Iterations', labelpad=10)\n",
    "        plt.ylabel('Flow Value', labelpad=10)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(loc='lower right', framealpha=1)\n",
    "\n",
    "        # Adjust limits to highlight convergence\n",
    "        y_min = min(values.min(), self.optimal_max_flow_value*0.9)\n",
    "        y_max = max(values.max(), self.optimal_max_flow_value*1.05)\n",
    "        plt.ylim(y_min, y_max)\n",
    "\n",
    "        # Add info box\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        info_text = (f\"Optimal: {self.optimal_max_flow_value:.2f}\\n\"\n",
    "                    f\"Reached at: {self.best_iteration} iter\\n\"\n",
    "                    f\"Evaluations: {self.evaluations}\\n\"\n",
    "                    f\"Time: {elapsed_time:.2f}s\")\n",
    "        plt.gcf().text(0.15, 0.7, info_text, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "        if filename:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def search(self, seed: Optional[int] = None) -> Tuple[float, np.array, int, int]:\n",
    "        \"\"\"Execute the improved Tabu Search algorithm with accurate tracking.\"\"\"\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        #print(f\"Starting search with {len(self.edges)} edges...\")\n",
    "        self.convergence_history = [self.best_value]\n",
    "        self.convergence_iterations = [0]\n",
    "        stagnation_counter = 0\n",
    "        max_stagnation = 1500\n",
    "        self.tabu_list = {}\n",
    "        self.start_time = time.time()\n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            diversified = self._adaptive_parameters(iteration, stagnation_counter)\n",
    "            if diversified:\n",
    "                stagnation_counter = 0\n",
    "                print(f\"Diversification applied at iteration {iteration}\")\n",
    "\n",
    "            moves = self._get_neighborhood_moves(self.current_flow, iteration)\n",
    "            if not moves:\n",
    "                print(f\"No available moves at iteration {iteration}\")\n",
    "                break\n",
    "\n",
    "            best_move_info = None\n",
    "            best_value_candidate = -float('inf')\n",
    "            best_flow_candidate = None\n",
    "            aspiration_move = False\n",
    "\n",
    "            for move_flow, move_info, delta, is_tabu in moves:\n",
    "                if not self._is_feasible(move_flow):\n",
    "                    continue\n",
    "\n",
    "                value = self._calculate_flow_value(move_flow)\n",
    "\n",
    "                if is_tabu and value > self.best_value:\n",
    "                    best_move_info = move_info\n",
    "                    best_value_candidate = value\n",
    "                    best_flow_candidate = move_flow\n",
    "                    aspiration_move = True\n",
    "                    break\n",
    "\n",
    "                if not is_tabu and value > best_value_candidate:\n",
    "                    best_move_info = move_info\n",
    "                    best_value_candidate = value\n",
    "                    best_flow_candidate = move_flow\n",
    "                    aspiration_move = False\n",
    "\n",
    "            if best_flow_candidate is None:\n",
    "                for move_flow, move_info, delta, is_tabu in moves:\n",
    "                    if self._is_feasible(move_flow):\n",
    "                        value = self._calculate_flow_value(move_flow)\n",
    "                        if value > best_value_candidate:\n",
    "                            best_move_info = move_info\n",
    "                            best_value_candidate = value\n",
    "                            best_flow_candidate = move_flow\n",
    "                            break\n",
    "\n",
    "                if best_flow_candidate is None:\n",
    "                    stagnation_counter += 1\n",
    "                    if stagnation_counter > max_stagnation:\n",
    "                        print(f\"Stopped due to stagnation at iteration {iteration}\")\n",
    "                        break\n",
    "                    continue\n",
    "\n",
    "            self.current_flow = best_flow_candidate\n",
    "            current_value = self._calculate_flow_value(self.current_flow)\n",
    "\n",
    "            if isinstance(best_move_info, int):\n",
    "                self.tabu_list[best_move_info] = iteration + self.tabu_tenure\n",
    "            elif isinstance(best_move_info, tuple):\n",
    "                for idx in best_move_info:\n",
    "                    self.tabu_list[idx] = iteration + self.tabu_tenure\n",
    "\n",
    "            if iteration % 100 == 0:\n",
    "                self.tabu_list = {k: v for k, v in self.tabu_list.items() if v > iteration}\n",
    "\n",
    "            if current_value > self.best_value:\n",
    "                self.best_value = current_value\n",
    "                np.copyto(self.best_flow, self.current_flow)\n",
    "                self.best_iteration = iteration\n",
    "                stagnation_counter = 0\n",
    "                #print(f\"New best: {self.best_value:.2f} at iteration {iteration}\")\n",
    "                #if aspiration_move:\n",
    "                #    print(\" (found via aspiration)\")\n",
    "            else:\n",
    "                stagnation_counter += 1\n",
    "\n",
    "            # Record convergence every 50 iterations AND at every improvement\n",
    "            if iteration % 50 == 0 or current_value > self.convergence_history[-1] or iteration == self.max_iterations - 1:\n",
    "                self.convergence_history.append(self.best_value)\n",
    "                self.convergence_iterations.append(iteration)\n",
    "\n",
    "            if abs(self.best_value - self.optimal_max_flow_value) < 1e-6:\n",
    "                print(f\"🎯 Optimal solution {self.optimal_max_flow_value:.2f} reached at iteration {iteration}\")\n",
    "                break\n",
    "\n",
    "            if self._check_optimality_condition(self.best_value):\n",
    "                print(f\"Optimality condition met at iteration {iteration}\")\n",
    "                break\n",
    "\n",
    "            if iteration % 2000 == 0 and iteration > 0:\n",
    "                print(f\"Iteration {iteration}: Best = {self.best_value:.2f}, \"\n",
    "                      f\"Stagnation = {stagnation_counter}, Tabu tenure = {self.tabu_tenure}\")\n",
    "\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        print(f\"Search completed after {iteration+1} iterations\")\n",
    "        print(f\"Best solution: {self.best_value:.2f}\")\n",
    "        print(f\"Objective function evaluations: {self.evaluations}\")\n",
    "        print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "        # Ensure final point is recorded\n",
    "        if self.convergence_iterations[-1] != iteration:\n",
    "            self.convergence_history.append(self.best_value)\n",
    "            self.convergence_iterations.append(iteration)\n",
    "\n",
    "        return float(self.best_value), self.best_flow, int(self.best_iteration), int(self.evaluations)\n",
    "\n",
    "def read_instance(filename: str) -> Tuple[Dict[Tuple[int, int], float], int, int, int, int]:\n",
    "    \"\"\"Read graph instance data from file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    n_nodes = int(lines[0])\n",
    "    n_edges = int(lines[1])\n",
    "    source = int(lines[2])\n",
    "    sink = int(lines[3])\n",
    "    graph = {}\n",
    "\n",
    "    for i in range(4, min(4 + n_edges, len(lines))):\n",
    "        parts = lines[i].split()\n",
    "        if len(parts) >= 3:\n",
    "            u, v, capacity = int(parts[0]), int(parts[1]), float(parts[2])\n",
    "            graph[(u, v)] = capacity\n",
    "\n",
    "    return graph, source, sink, n_nodes, n_edges\n",
    "\n",
    "def convert_numpy_types(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON serialization\"\"\"\n",
    "    if isinstance(obj, np.generic):\n",
    "        return obj.item()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_numpy_types(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_types(v) for v in obj]\n",
    "    return obj\n",
    "\n",
    "def plot_average_convergence(results: List[Dict], filename: str, optimal_value: float) -> None:\n",
    "    \"\"\"Plot average convergence across multiple runs with correct iteration mapping.\"\"\"\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    # Find maximum iteration count across all runs\n",
    "    max_iter = max(len(r['convergence_iterations']) for r in results)\n",
    "\n",
    "    # Prepare matrix for interpolation\n",
    "    all_values = []\n",
    "    for r in results:\n",
    "        x_orig = np.array(r['convergence_iterations'])\n",
    "        y_orig = np.array(r['convergence_history'])\n",
    "\n",
    "        # Create interpolation function\n",
    "        x_new = np.linspace(0, x_orig[-1], max_iter)\n",
    "        y_interp = np.interp(x_new, x_orig, y_orig)\n",
    "        all_values.append(y_interp)\n",
    "\n",
    "    # Calculate statistics\n",
    "    avg_convergence = np.mean(all_values, axis=0)\n",
    "    std_convergence = np.std(all_values, axis=0)\n",
    "    x_values = np.linspace(0, x_new[-1], max_iter)\n",
    "\n",
    "    # Plot with shaded standard deviation\n",
    "    plt.plot(x_values, avg_convergence, 'b-', linewidth=2, label='Average Flow')\n",
    "    plt.fill_between(x_values, avg_convergence - std_convergence,\n",
    "                    avg_convergence + std_convergence, alpha=0.2)\n",
    "\n",
    "    # Optimal value line\n",
    "    plt.axhline(y=optimal_value, color='r', linestyle='--',\n",
    "               linewidth=1.5, label=f'Optimal (EK): {optimal_value:.2f}')\n",
    "\n",
    "    # Find and mark convergence point\n",
    "    convergence_idx = np.where(avg_convergence >= optimal_value - 1e-6)[0]\n",
    "    if len(convergence_idx) > 0:\n",
    "        conv_iter = int(x_values[convergence_idx[0]])\n",
    "        plt.scatter([conv_iter], [optimal_value], color='g',\n",
    "                   s=100, zorder=5, label=f'Convergence at {conv_iter}')\n",
    "\n",
    "    plt.title(f'Average Convergence for {os.path.basename(filename)}\\n'\n",
    "             f'{len(results)} runs', pad=20)\n",
    "    plt.xlabel('Iterations', labelpad=10)\n",
    "    plt.ylabel('Flow Value', labelpad=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def run_experiments(output_dir: str = \"results\") -> Dict[str, Dict]:\n",
    "    \"\"\"Run experiments for all found instances with accurate convergence tracking.\"\"\"\n",
    "    print(\"=== IMPROVED TABU SEARCH FOR MAXIMUM FLOW ===\")\n",
    "    print(\"Version with precise convergence tracking and visualization\")\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    instance_files = glob.glob(\"network_*.txt\")\n",
    "    if not instance_files:\n",
    "        print(\"No 'network_*.txt' instances found in current directory.\")\n",
    "        return {}\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for filename in sorted(instance_files):\n",
    "        print(f\"\\n--- Processing instance: {filename} ---\")\n",
    "        try:\n",
    "            graph, source, sink, n_nodes, n_edges = read_instance(filename)\n",
    "            print(f\"Graph: Nodes={n_nodes}, Edges={n_edges}\")\n",
    "            print(f\"Source={source}, Sink={sink}\")\n",
    "\n",
    "            runs_results = []\n",
    "            num_runs = 10\n",
    "\n",
    "            for run in range(num_runs):\n",
    "                print(f\"\\n--- Run {run + 1}/{num_runs} for {filename} ---\")\n",
    "                solver = MaxFlowTabuSearch(graph, source, sink,\n",
    "                                         tabu_tenure=20, max_iterations=20000)\n",
    "                seed = run + 42\n",
    "                best_value, best_flow, best_iteration, evaluations = solver.search(seed=seed)\n",
    "\n",
    "                runs_results.append({\n",
    "                    'best_value': float(best_value),\n",
    "                    'best_iteration': int(best_iteration),\n",
    "                    'evaluations': int(evaluations),\n",
    "                    'optimal_max_flow_value': float(solver.optimal_max_flow_value),\n",
    "                    'convergence_history': [float(x) for x in solver.convergence_history],\n",
    "                    'convergence_iterations': [int(x) for x in solver.convergence_iterations]\n",
    "                })\n",
    "\n",
    "                # Save individual run plot\n",
    "                plot_path = os.path.join(output_dir, f\"{os.path.basename(filename)}_run{run+1}_convergence.png\")\n",
    "                solver.plot_convergence(plot_path, title_suffix=f\"({os.path.basename(filename)}, Run {run+1})\")\n",
    "\n",
    "                print(f\"Run {run + 1} result: Flow={best_value:.2f}, Iter={best_iteration}, Eval={evaluations}\")\n",
    "\n",
    "            # Create average convergence plot\n",
    "            avg_plot_path = os.path.join(output_dir, f\"{os.path.basename(filename)}_average_convergence.png\")\n",
    "            plot_average_convergence(runs_results, avg_plot_path, runs_results[0]['optimal_max_flow_value'])\n",
    "\n",
    "            # Calculate statistics\n",
    "            best_values = [r['best_value'] for r in runs_results]\n",
    "            best_iterations = [r['best_iteration'] for r in runs_results]\n",
    "            evaluations_list = [r['evaluations'] for r in runs_results]\n",
    "            optimal_value = runs_results[0]['optimal_max_flow_value']\n",
    "\n",
    "            gaps = [(optimal_value - bv) / optimal_value * 100 if optimal_value > 0 else 0\n",
    "                   for bv in best_values]\n",
    "\n",
    "            result = {\n",
    "                'best': float(max(best_values)),\n",
    "                'mean': float(np.mean(best_values)),\n",
    "                'std': float(np.std(best_values)),\n",
    "                'avg_iterations': float(np.mean(best_iterations)),\n",
    "                'avg_evaluations': float(np.mean(evaluations_list)),\n",
    "                'optimal_value_ek': float(optimal_value),\n",
    "                'avg_gap': float(np.mean(gaps)),\n",
    "                'best_gap': float(min(gaps)),\n",
    "                'n_nodes': int(n_nodes),\n",
    "                'n_edges': int(n_edges),\n",
    "                'success_rate': float(sum(1 for gap in gaps if gap < 0.01) / len(gaps) * 100),\n",
    "                'convergence_plot': avg_plot_path\n",
    "            }\n",
    "\n",
    "            results[filename] = result\n",
    "\n",
    "            # Save results\n",
    "            instance_result_path = os.path.join(output_dir, f\"{os.path.basename(filename)}_results.json\")\n",
    "            with open(instance_result_path, 'w') as f:\n",
    "                json.dump(convert_numpy_types(result), f, indent=2)\n",
    "\n",
    "            print(f\"\\n--- Final statistics for {filename} ---\")\n",
    "            print(f\"Optimal (Edmonds-Karp): {result['optimal_value_ek']:.2f}\")\n",
    "            print(f\"Best Flow (TS): {result['best']:.2f}\")\n",
    "            print(f\"Mean Flow (TS): {result['mean']:.2f} ± {result['std']:.2f}\")\n",
    "            print(f\"Standard Deviation: {result['std']:.2f}\")\n",
    "            #print(f\"Average optimality gap: {result['avg_gap']:.2f}%\")\n",
    "            #print(f\"Best gap: {result['best_gap']:.2f}%\")\n",
    "            #print(f\"Success rate (<0.01%): {result['success_rate']:.1f}%\")\n",
    "            print(f\"Average iterations: {result['avg_iterations']:.0f}\")\n",
    "            print(f\"Average evaluations: {result['avg_evaluations']:.0f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    experiment_results = run_experiments()\n",
    "\n",
    "    print(\"\\n=== EXPERIMENT SUMMARY ===\")\n",
    "    for filename, res in experiment_results.items():\n",
    "        print(f\"\\n{os.path.basename(filename)}:\")\n",
    "        print(f\"Nodes: {res['n_nodes']}, Edges: {res['n_edges']}\")\n",
    "        print(f\"Optimal EK: {res['optimal_value_ek']:.2f}\")\n",
    "        print(f\"Best TS: {res['best']:.2f} (gap: {res['best_gap']:.2f}%)\")\n",
    "        print(f\"Mean TS: {res['mean']:.2f}±{res['std']:.2f}\")\n",
    "        print(f\"Standard Deviation: {res['std']:.2f}\")\n",
    "        #print(f\"Success: {res['success_rate']:.1f}%\")\n",
    "        #print(f\"Evals: {res['avg_evaluations']:.0f}\")\n",
    "        print(f\"Average iterations: {res['avg_iterations']:.0f}\")\n",
    "        print(f\"Average evaluations: {res['avg_evaluations']:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f657ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque, defaultdict\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import json\n",
    "\n",
    "\n",
    "class MaxFlowTabuSearchOptimized:\n",
    "    def __init__(self, graph: Dict[Tuple[int, int], float], source: int, sink: int,\n",
    "                 tabu_tenure=20, max_iterations=20000):\n",
    "        self.source = source\n",
    "        self.sink = sink\n",
    "        self.graph = graph\n",
    "        self.edges = list(graph.keys())\n",
    "        self.capacities = np.array([graph[e] for e in self.edges], dtype=np.float32)\n",
    "        self.edge_to_idx = {(u, v): i for i, (u, v) in enumerate(self.edges)}\n",
    "        self.source_edges = [i for i, (u, v) in enumerate(self.edges) if u == self.source]\n",
    "        self.n_edges = len(self.edges)\n",
    "        self.tabu_tenure = tabu_tenure\n",
    "        self.max_iterations = max_iterations\n",
    "        self.current_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        self.best_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        self.best_value = 0.0\n",
    "        self.convergence_history = []\n",
    "        self.convergence_iterations = []\n",
    "        self.evaluations = 0\n",
    "        self.best_iteration = 0\n",
    "        self.start_time = time.time()\n",
    "        self._precompute_adjacency()\n",
    "        self.optimal_max_flow_value = self._run_edmonds_karp()\n",
    "        self.source_out_capacity = sum(cap for (u, v), cap in self.graph.items() if u == self.source)\n",
    "        self.sink_in_capacity = sum(cap for (u, v), cap in self.graph.items() if v == self.sink)\n",
    "        self._init_with_partial_edmonds_karp()\n",
    "\n",
    "    def _precompute_adjacency(self):\n",
    "        self.adj = defaultdict(set)\n",
    "        for (u, v) in self.graph:\n",
    "            self.adj[u].add(v)\n",
    "\n",
    "    def _run_edmonds_karp(self):\n",
    "        residual = defaultdict(float)\n",
    "        for (u, v), cap in self.graph.items():\n",
    "            residual[(u, v)] = cap\n",
    "            residual[(v, u)] = 0.0\n",
    "        flow = 0.0\n",
    "        while True:\n",
    "            parent = {}\n",
    "            visited = {self.source}\n",
    "            queue = deque([self.source])\n",
    "            found = False\n",
    "            while queue and not found:\n",
    "                u = queue.popleft()\n",
    "                for v in self.adj[u]:\n",
    "                    if residual[(u, v)] > 1e-6 and v not in visited:\n",
    "                        visited.add(v)\n",
    "                        parent[v] = u\n",
    "                        if v == self.sink:\n",
    "                            found = True\n",
    "                            break\n",
    "                        queue.append(v)\n",
    "            if not found:\n",
    "                break\n",
    "            path_flow = float('inf')\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                path_flow = min(path_flow, residual[(u, v)])\n",
    "                v = u\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                residual[(u, v)] -= path_flow\n",
    "                residual[(v, u)] += path_flow\n",
    "                v = u\n",
    "            flow += path_flow\n",
    "        return flow\n",
    "\n",
    "    def _init_with_partial_edmonds_karp(self):\n",
    "        optimal_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        residual = defaultdict(float)\n",
    "        for idx, (u, v) in enumerate(self.edges):\n",
    "            residual[(u, v)] = self.capacities[idx]\n",
    "            residual[(v, u)] = 0.0\n",
    "        while True:\n",
    "            parent = {}\n",
    "            visited = {self.source}\n",
    "            queue = deque([self.source])\n",
    "            found = False\n",
    "            while queue and not found:\n",
    "                u = queue.popleft()\n",
    "                for v in self.adj[u]:\n",
    "                    if residual[(u, v)] > 1e-6 and v not in visited:\n",
    "                        visited.add(v)\n",
    "                        parent[v] = u\n",
    "                        if v == self.sink:\n",
    "                            found = True\n",
    "                            break\n",
    "                        queue.append(v)\n",
    "            if not found:\n",
    "                break\n",
    "            path_flow = float('inf')\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                path_flow = min(path_flow, residual[(u, v)])\n",
    "                v = u\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                edge = (u, v)\n",
    "                idx = self.edge_to_idx.get(edge, -1)\n",
    "                if idx >= 0:\n",
    "                    residual[(u, v)] -= path_flow\n",
    "                    residual[(v, u)] += path_flow\n",
    "                    optimal_flow[idx] += path_flow\n",
    "                v = u\n",
    "        factor = random.uniform(0.7, 0.95)\n",
    "        self.current_flow[:] = optimal_flow * factor\n",
    "        self.best_value = self._calculate_flow_value(self.current_flow)\n",
    "        self.best_flow[:] = self.current_flow\n",
    "        self.convergence_history = [self.best_value]\n",
    "        self.convergence_iterations = [0]\n",
    "\n",
    "    def _calculate_flow_value(self, flow):\n",
    "        self.evaluations += 1\n",
    "        return np.sum(flow[self.source_edges])\n",
    "\n",
    "    def _get_neighborhood_moves(self, current_flow):\n",
    "        moves = []\n",
    "        sample_size = min(len(self.edges), max(50, len(self.edges) // 40))\n",
    "        sampled_edges = random.sample(range(len(self.edges)), sample_size)\n",
    "        for edge_idx in sampled_edges:\n",
    "            curr = current_flow[edge_idx]\n",
    "            cap = self.capacities[edge_idx]\n",
    "            if curr < cap - 1e-6:\n",
    "                step = min(cap - curr, cap * 0.2)\n",
    "                new_flow = current_flow.copy()\n",
    "                new_flow[edge_idx] += step\n",
    "                is_tabu = edge_idx in self.tabu_dict and self.tabu_dict[edge_idx] > 0\n",
    "                moves.append((new_flow, edge_idx, step, is_tabu))\n",
    "            if curr > 1e-6:\n",
    "                step = min(curr, cap * 0.2)\n",
    "                new_flow = current_flow.copy()\n",
    "                new_flow[edge_idx] -= step\n",
    "                is_tabu = edge_idx in self.tabu_dict and self.tabu_dict[edge_idx] > 0\n",
    "                moves.append((new_flow, edge_idx, -step, is_tabu))\n",
    "        if self.n_edges <= 1000 and len(sampled_edges) >= 2:\n",
    "            edge1, edge2 = random.sample(sampled_edges, 2)\n",
    "            if current_flow[edge1] > 1e-6 and current_flow[edge2] < self.capacities[edge2] - 1e-6:\n",
    "                transfer = min(current_flow[edge1], self.capacities[edge2] - current_flow[edge2]) * 0.3\n",
    "                new_flow = current_flow.copy()\n",
    "                new_flow[edge1] -= transfer\n",
    "                new_flow[edge2] += transfer\n",
    "                moves.append((new_flow, (edge1, edge2), transfer, False))\n",
    "        return moves\n",
    "\n",
    "    def _diversify_solution(self, current_flow):\n",
    "        reset_factor = random.uniform(0.5, 0.8)\n",
    "        noise_factor = random.uniform(0.1, 0.2)\n",
    "        new_flow = current_flow * (1 - reset_factor)\n",
    "        num_perturb = min(len(self.edges) // 10, 10)\n",
    "        indices = random.sample(range(len(self.edges)), num_perturb)\n",
    "        for idx in indices:\n",
    "            cap = self.capacities[idx]\n",
    "            noise = random.uniform(-noise_factor, noise_factor) * cap\n",
    "            new_flow[idx] = max(0, min(cap, new_flow[idx] + noise))\n",
    "        return new_flow\n",
    "\n",
    "    def plot_convergence(self, filename=None, title_suffix=\"\"):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.convergence_iterations, self.convergence_history, label='Best Flow', color='blue')\n",
    "        plt.axhline(y=self.optimal_max_flow_value, color='red', linestyle='--', label='Optimal (Edmonds-Karp)')\n",
    "        #plt.axhline(y=min(self.source_out_capacity, self.sink_in_capacity), \n",
    "        #           color='green', linestyle=':', label='Upper Bound')\n",
    "        plt.title(f'Convergence {title_suffix}')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Flow Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        if filename:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def search(self, seed=None):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "        stagnation_counter = 0\n",
    "        max_stagnation = 1000\n",
    "        self.tabu_dict = defaultdict(int)\n",
    "        upper_bound = min(self.source_out_capacity, self.sink_in_capacity)\n",
    "        for iteration in range(self.max_iterations):\n",
    "            if stagnation_counter >= max_stagnation:\n",
    "                self.current_flow = self._diversify_solution(self.current_flow)\n",
    "                stagnation_counter = 0\n",
    "            moves = self._get_neighborhood_moves(self.current_flow)\n",
    "            if not moves:\n",
    "                break\n",
    "            best_move = None\n",
    "            best_val = -np.inf\n",
    "            for move_flow, idx, delta, is_tabu in moves:\n",
    "                val = self._calculate_flow_value(move_flow)\n",
    "                if (not is_tabu or val > self.best_value) and val > best_val:\n",
    "                    best_val = val\n",
    "                    best_move = (move_flow, idx)\n",
    "            if best_move is None:\n",
    "                stagnation_counter += 1\n",
    "                continue\n",
    "            new_flow, edge_idx = best_move\n",
    "            self.current_flow = new_flow\n",
    "            if isinstance(edge_idx, tuple):\n",
    "                for e in edge_idx:\n",
    "                    self.tabu_dict[e] = self.tabu_tenure\n",
    "            else:\n",
    "                self.tabu_dict[edge_idx] = self.tabu_tenure\n",
    "            self.tabu_dict = {k: v-1 for k, v in self.tabu_dict.items() if v > 1}\n",
    "            current_val = self._calculate_flow_value(self.current_flow)\n",
    "            if current_val > self.best_value:\n",
    "                self.best_value = current_val\n",
    "                self.best_flow[:] = self.current_flow\n",
    "                self.best_iteration = iteration\n",
    "                stagnation_counter = 0\n",
    "            else:\n",
    "                stagnation_counter += 1\n",
    "            if iteration % 100 == 0 or current_val > self.convergence_history[-1]:\n",
    "                self.convergence_history.append(current_val)\n",
    "                self.convergence_iterations.append(iteration)\n",
    "            if abs(current_val - upper_bound) < 1e-6:\n",
    "                break\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        return {\n",
    "            'convergence_history': self.convergence_history,\n",
    "            'convergence_iterations': self.convergence_iterations,\n",
    "            'best_value': self.best_value,\n",
    "            'best_flow': self.best_flow,\n",
    "            'best_iteration': self.best_iteration,\n",
    "            'evaluations': self.evaluations,\n",
    "            'elapsed_time': elapsed_time,\n",
    "            'source_out_capacity': self.source_out_capacity,\n",
    "            'sink_in_capacity': self.sink_in_capacity,\n",
    "            'optimal_flow': self.optimal_max_flow_value\n",
    "        }\n",
    "\n",
    "\n",
    "def read_instance(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    n_nodes = int(lines[0])\n",
    "    n_edges = int(lines[1])\n",
    "    source = int(lines[2])\n",
    "    sink = int(lines[3])\n",
    "    graph = {}\n",
    "    for i in range(4, min(4 + n_edges, len(lines))):\n",
    "        parts = lines[i].split()\n",
    "        if len(parts) >= 3:\n",
    "            u, v, capacity = int(parts[0]), int(parts[1]), float(parts[2])\n",
    "            graph[(u, v)] = capacity\n",
    "    return graph, source, sink, n_nodes, n_edges\n",
    "\n",
    "\n",
    "def run_single_experiment(args):\n",
    "    graph, source, sink, seed, output_dir, filename_base, run = args\n",
    "    solver = MaxFlowTabuSearchOptimized(graph, source, sink)\n",
    "    result = solver.search(seed=seed)\n",
    "    plot_path = os.path.join(output_dir, f\"{filename_base}_run{run+1}_convergence.png\")\n",
    "    solver.plot_convergence(plot_path, title_suffix=f\"(Run {run+1})\")\n",
    "    print(f\"Run {run + 1}: Best={result['best_value']:.2f}, Iter={result['best_iteration']}, \"\n",
    "          f\"Eval={result['evaluations']}, Time={result['elapsed_time']:.4f}s\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_mean_convergence(runs_results, max_iterations):\n",
    "    common_iterations = np.linspace(0, max_iterations, 1000)\n",
    "    all_flows = []\n",
    "    \n",
    "    for run in runs_results:\n",
    "        interp_flow = np.interp(\n",
    "            common_iterations,\n",
    "            run['convergence_iterations'],\n",
    "            run['convergence_history'],\n",
    "            right=run['convergence_history'][-1]\n",
    "        )\n",
    "        all_flows.append(interp_flow)\n",
    "    \n",
    "    mean_flow = np.mean(all_flows, axis=0)\n",
    "    std_flow = np.std(all_flows, axis=0)\n",
    "    \n",
    "    return common_iterations, mean_flow, std_flow\n",
    "\n",
    "\n",
    "def get_best_run(runs_results):\n",
    "    scores = [r['best_value'] - (0.0001 * r['best_iteration']) for r in runs_results]\n",
    "    best_idx = np.argmax(scores)\n",
    "    return runs_results[best_idx]\n",
    "\n",
    "\n",
    "def run_experiments(output_dir=\"results\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    instance_files = [f for f in os.listdir() if f.startswith(\"network_\") and f.endswith(\".txt\")]\n",
    "    results = {}\n",
    "    \n",
    "    for filename in sorted(instance_files):\n",
    "        print(f\"\\n--- Processing instance: {filename} ---\")\n",
    "        try:\n",
    "            graph, source, sink, n_nodes, n_edges = read_instance(filename)\n",
    "            args_list = [(graph, source, sink, run + 42, output_dir, \n",
    "                         os.path.splitext(filename)[0], run) for run in range(10)]\n",
    "            \n",
    "            with Pool(max(1, cpu_count() // 2)) as p:\n",
    "                runs_results = p.map(run_single_experiment, args_list)\n",
    "\n",
    "            # Salva i dati grezzi\n",
    "            #raw_data_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_raw_data.json\")\n",
    "            #with open(raw_data_path, 'w') as f:\n",
    "            #    json.dump({\n",
    "            #        'runs': runs_results,\n",
    "            #        'optimal_flow': runs_results[0]['optimal_flow'],\n",
    "            #        'upper_bound': min(runs_results[0]['source_out_capacity'], \n",
    "            #                         runs_results[0]['sink_in_capacity'])\n",
    "            #    }, f)\n",
    "\n",
    "            # Calcola convergenza media corretta\n",
    "            max_iter = max([r['convergence_iterations'][-1] for r in runs_results])\n",
    "            x_vals, mean_conv, std_conv = compute_mean_convergence(runs_results, max_iter)\n",
    "\n",
    "            # Plot convergenza media\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(x_vals, mean_conv, label='Mean Flow', color='blue')\n",
    "            #plt.fill_between(x_vals, mean_conv - std_conv, mean_conv + std_conv, \n",
    "            #               alpha=0.2, color='blue', label='±1 Std Dev')\n",
    "            plt.axhline(y=runs_results[0]['optimal_flow'], color='red', \n",
    "                       linestyle='--', label='Optimal (Edmonds-Karp)')\n",
    "            #plt.axhline(y=min(runs_results[0]['source_out_capacity'], \n",
    "            #           runs_results[0]['sink_in_capacity']),\n",
    "            #           color='green', linestyle=':', label='Upper Bound')\n",
    "            plt.title(f'Mean Convergence for {filename}')\n",
    "            plt.xlabel('Iterations')\n",
    "            plt.ylabel('Flow Value')\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            mean_plot_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_mean_convergence.png\")\n",
    "            plt.savefig(mean_plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            # Plot miglior run (selezionata correttamente)\n",
    "            best_run = get_best_run(runs_results)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(best_run['convergence_iterations'], best_run['convergence_history'],\n",
    "                    label=f'Best Run (Flow={best_run[\"best_value\"]:.2f})', color='blue')\n",
    "            plt.axhline(y=best_run['optimal_flow'], color='red', \n",
    "                       linestyle='--', label='Optimal')\n",
    "            #plt.axhline(y=min(best_run['source_out_capacity'], best_run['sink_in_capacity']),\n",
    "            #           color='green', linestyle=':', label='Upper Bound')\n",
    "            plt.title(f'Best Run Convergence for {filename}\\n'\n",
    "                     f'Final Flow: {best_run[\"best_value\"]:.2f} | '\n",
    "                     f'Optimal: {best_run[\"optimal_flow\"]:.2f} | '\n",
    "                     f'Iter: {best_run[\"best_iteration\"]}')\n",
    "            plt.xlabel('Iterations')\n",
    "            plt.ylabel('Flow Value')\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            best_plot_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_best_convergence.png\")\n",
    "            plt.savefig(best_plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            # Statistiche finali\n",
    "            all_flows = [r['best_value'] for r in runs_results]\n",
    "            result = {\n",
    "                'best': max(all_flows),\n",
    "                'mean': np.mean(all_flows),\n",
    "                'std': np.std(all_flows),\n",
    "                'optimal': runs_results[0]['optimal_flow'],\n",
    "                'upper_bound': min(runs_results[0]['source_out_capacity'], \n",
    "                                 runs_results[0]['sink_in_capacity']),\n",
    "                'avg_iterations': np.mean([r['best_iteration'] for r in runs_results]),\n",
    "                'avg_evaluations': np.mean([r['evaluations'] for r in runs_results]),\n",
    "                'avg_time': np.mean([r['elapsed_time'] for r in runs_results])\n",
    "            }\n",
    "            results[filename] = result\n",
    "            \n",
    "            print(f\"\\nFinal statistics for {filename}:\")\n",
    "            print(f\"Best Flow (TS): {result['best']:.2f} (Optimal: {result['optimal']:.2f})\")\n",
    "            print(f\"Mean Flow (TS): {result['mean']:.2f} ± {result['std']:.2f}\")\n",
    "            print(f\"Upper Bound: {result['upper_bound']:.2f}\")\n",
    "            print(f\"Avg Iterations: {result['avg_iterations']:.0f}\")\n",
    "            print(f\"Avg Evaluations: {result['avg_evaluations']:.0f}\")\n",
    "            print(f\"Avg Time: {result['avg_time']:.4f}s\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    experiment_results = run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38290f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque, defaultdict\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import json\n",
    "\n",
    "\n",
    "class MaxFlowTabuSearchOptimized:\n",
    "    def __init__(self, graph: Dict[Tuple[int, int], float], source: int, sink: int,\n",
    "                 tabu_tenure=20, max_iterations=20000):\n",
    "        self.source = source\n",
    "        self.sink = sink\n",
    "        self.graph = graph\n",
    "        self.edges = list(graph.keys())\n",
    "        self.capacities = np.array([graph[e] for e in self.edges], dtype=np.float32)\n",
    "        self.edge_to_idx = {(u, v): i for i, (u, v) in enumerate(self.edges)}\n",
    "        self.source_edges = [i for i, (u, v) in enumerate(self.edges) if u == self.source]\n",
    "        self.n_edges = len(self.edges)\n",
    "        self.tabu_tenure = tabu_tenure\n",
    "        self.max_iterations = max_iterations\n",
    "        self.current_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        self.best_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        self.best_value = 0.0\n",
    "        self.convergence_history = []\n",
    "        self.convergence_iterations = []\n",
    "        self.evaluations = 0\n",
    "        self.best_iteration = 0\n",
    "        self.start_time = time.time()\n",
    "        self._precompute_adjacency()\n",
    "        self.optimal_max_flow_value = self._run_edmonds_karp()\n",
    "        self.source_out_capacity = sum(cap for (u, v), cap in self.graph.items() if u == self.source)\n",
    "        self.sink_in_capacity = sum(cap for (u, v), cap in self.graph.items() if v == self.sink)\n",
    "        self._init_with_partial_edmonds_karp()\n",
    "\n",
    "    def _precompute_adjacency(self):\n",
    "        self.adj = defaultdict(set)\n",
    "        for (u, v) in self.graph:\n",
    "            self.adj[u].add(v)\n",
    "\n",
    "    def _run_edmonds_karp(self):\n",
    "        residual = defaultdict(float)\n",
    "        for (u, v), cap in self.graph.items():\n",
    "            residual[(u, v)] = cap\n",
    "            residual[(v, u)] = 0.0\n",
    "        flow = 0.0\n",
    "        while True:\n",
    "            parent = {}\n",
    "            visited = {self.source}\n",
    "            queue = deque([self.source])\n",
    "            found = False\n",
    "            while queue and not found:\n",
    "                u = queue.popleft()\n",
    "                for v in self.adj[u]:\n",
    "                    if residual[(u, v)] > 1e-6 and v not in visited:\n",
    "                        visited.add(v)\n",
    "                        parent[v] = u\n",
    "                        if v == self.sink:\n",
    "                            found = True\n",
    "                            break\n",
    "                        queue.append(v)\n",
    "            if not found:\n",
    "                break\n",
    "            path_flow = float('inf')\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                path_flow = min(path_flow, residual[(u, v)])\n",
    "                v = u\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                residual[(u, v)] -= path_flow\n",
    "                residual[(v, u)] += path_flow\n",
    "                v = u\n",
    "            flow += path_flow\n",
    "        return flow\n",
    "\n",
    "    def _init_with_partial_edmonds_karp(self):\n",
    "        optimal_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        residual = defaultdict(float)\n",
    "        for idx, (u, v) in enumerate(self.edges):\n",
    "            residual[(u, v)] = self.capacities[idx]\n",
    "            residual[(v, u)] = 0.0\n",
    "        while True:\n",
    "            parent = {}\n",
    "            visited = {self.source}\n",
    "            queue = deque([self.source])\n",
    "            found = False\n",
    "            while queue and not found:\n",
    "                u = queue.popleft()\n",
    "                for v in self.adj[u]:\n",
    "                    if residual[(u, v)] > 1e-6 and v not in visited:\n",
    "                        visited.add(v)\n",
    "                        parent[v] = u\n",
    "                        if v == self.sink:\n",
    "                            found = True\n",
    "                            break\n",
    "                        queue.append(v)\n",
    "            if not found:\n",
    "                break\n",
    "            path_flow = float('inf')\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                path_flow = min(path_flow, residual[(u, v)])\n",
    "                v = u\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                edge = (u, v)\n",
    "                idx = self.edge_to_idx.get(edge, -1)\n",
    "                if idx >= 0:\n",
    "                    residual[(u, v)] -= path_flow\n",
    "                    residual[(v, u)] += path_flow\n",
    "                    optimal_flow[idx] += path_flow\n",
    "                v = u\n",
    "        factor = random.uniform(0.7, 0.95)\n",
    "        self.current_flow[:] = optimal_flow * factor\n",
    "        self.best_value = self._calculate_flow_value(self.current_flow)\n",
    "        self.best_flow[:] = self.current_flow\n",
    "        self.convergence_history = [self.best_value]\n",
    "        self.convergence_iterations = [0]\n",
    "\n",
    "    def _calculate_flow_value(self, flow):\n",
    "        self.evaluations += 1\n",
    "        return np.sum(flow[self.source_edges])\n",
    "\n",
    "    def _get_neighborhood_moves(self, current_flow):\n",
    "        moves = []\n",
    "        sample_size = min(len(self.edges), max(50, len(self.edges) // 40))\n",
    "        sampled_edges = random.sample(range(len(self.edges)), sample_size)\n",
    "        for edge_idx in sampled_edges:\n",
    "            curr = current_flow[edge_idx]\n",
    "            cap = self.capacities[edge_idx]\n",
    "            if curr < cap - 1e-6:\n",
    "                step = min(cap - curr, cap * 0.2)\n",
    "                new_flow = current_flow.copy()\n",
    "                new_flow[edge_idx] += step\n",
    "                is_tabu = edge_idx in self.tabu_dict and self.tabu_dict[edge_idx] > 0\n",
    "                moves.append((new_flow, edge_idx, step, is_tabu))\n",
    "            if curr > 1e-6:\n",
    "                step = min(curr, cap * 0.2)\n",
    "                new_flow = current_flow.copy()\n",
    "                new_flow[edge_idx] -= step\n",
    "                is_tabu = edge_idx in self.tabu_dict and self.tabu_dict[edge_idx] > 0\n",
    "                moves.append((new_flow, edge_idx, -step, is_tabu))\n",
    "        if self.n_edges <= 1000 and len(sampled_edges) >= 2:\n",
    "            edge1, edge2 = random.sample(sampled_edges, 2)\n",
    "            if current_flow[edge1] > 1e-6 and current_flow[edge2] < self.capacities[edge2] - 1e-6:\n",
    "                transfer = min(current_flow[edge1], self.capacities[edge2] - current_flow[edge2]) * 0.3\n",
    "                new_flow = current_flow.copy()\n",
    "                new_flow[edge1] -= transfer\n",
    "                new_flow[edge2] += transfer\n",
    "                moves.append((new_flow, (edge1, edge2), transfer, False))\n",
    "        return moves\n",
    "\n",
    "    def _diversify_solution(self, current_flow):\n",
    "        reset_factor = random.uniform(0.5, 0.8)\n",
    "        noise_factor = random.uniform(0.1, 0.2)\n",
    "        new_flow = current_flow * (1 - reset_factor)\n",
    "        num_perturb = min(len(self.edges) // 10, 10)\n",
    "        indices = random.sample(range(len(self.edges)), num_perturb)\n",
    "        for idx in indices:\n",
    "            cap = self.capacities[idx]\n",
    "            noise = random.uniform(-noise_factor, noise_factor) * cap\n",
    "            new_flow[idx] = max(0, min(cap, new_flow[idx] + noise))\n",
    "        return new_flow\n",
    "\n",
    "    def plot_convergence(self, filename=None, title_suffix=\"\"):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.convergence_iterations, self.convergence_history, label='Best Flow', color='blue')\n",
    "        plt.axhline(y=self.optimal_max_flow_value, color='red', linestyle='--', label='Optimal (Edmonds-Karp)')\n",
    "        #plt.axhline(y=min(self.source_out_capacity, self.sink_in_capacity), \n",
    "        #           color='green', linestyle=':', label='Upper Bound')\n",
    "        plt.title(f'Convergence {title_suffix}')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Flow Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        if filename:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def search(self, seed=None):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "        stagnation_counter = 0\n",
    "        max_stagnation = 1000\n",
    "        self.tabu_dict = defaultdict(int)\n",
    "        upper_bound = min(self.source_out_capacity, self.sink_in_capacity)\n",
    "        for iteration in range(self.max_iterations):\n",
    "            if stagnation_counter >= max_stagnation:\n",
    "                self.current_flow = self._diversify_solution(self.current_flow)\n",
    "                stagnation_counter = 0\n",
    "            moves = self._get_neighborhood_moves(self.current_flow)\n",
    "            if not moves:\n",
    "                break\n",
    "            best_move = None\n",
    "            best_val = -np.inf\n",
    "            for move_flow, idx, delta, is_tabu in moves:\n",
    "                val = self._calculate_flow_value(move_flow)\n",
    "                if (not is_tabu or val > self.best_value) and val > best_val:\n",
    "                    best_val = val\n",
    "                    best_move = (move_flow, idx)\n",
    "            if best_move is None:\n",
    "                stagnation_counter += 1\n",
    "                continue\n",
    "            new_flow, edge_idx = best_move\n",
    "            self.current_flow = new_flow\n",
    "            if isinstance(edge_idx, tuple):\n",
    "                for e in edge_idx:\n",
    "                    self.tabu_dict[e] = self.tabu_tenure\n",
    "            else:\n",
    "                self.tabu_dict[edge_idx] = self.tabu_tenure\n",
    "            self.tabu_dict = {k: v-1 for k, v in self.tabu_dict.items() if v > 1}\n",
    "            current_val = self._calculate_flow_value(self.current_flow)\n",
    "            if current_val > self.best_value:\n",
    "                self.best_value = current_val\n",
    "                self.best_flow[:] = self.current_flow\n",
    "                self.best_iteration = iteration\n",
    "                stagnation_counter = 0\n",
    "            else:\n",
    "                stagnation_counter += 1\n",
    "            if iteration % 100 == 0 or current_val > self.convergence_history[-1]:\n",
    "                self.convergence_history.append(current_val)\n",
    "                self.convergence_iterations.append(iteration)\n",
    "            if abs(current_val - upper_bound) < 1e-6:\n",
    "                break\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        return {\n",
    "            'convergence_history': self.convergence_history,\n",
    "            'convergence_iterations': self.convergence_iterations,\n",
    "            'best_value': self.best_value,\n",
    "            'best_flow': self.best_flow,\n",
    "            'best_iteration': self.best_iteration,\n",
    "            'evaluations': self.evaluations,\n",
    "            'elapsed_time': elapsed_time,\n",
    "            'source_out_capacity': self.source_out_capacity,\n",
    "            'sink_in_capacity': self.sink_in_capacity,\n",
    "            'optimal_flow': self.optimal_max_flow_value\n",
    "        }\n",
    "\n",
    "\n",
    "def read_instance(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    n_nodes = int(lines[0])\n",
    "    n_edges = int(lines[1])\n",
    "    source = int(lines[2])\n",
    "    sink = int(lines[3])\n",
    "    graph = {}\n",
    "    for i in range(4, min(4 + n_edges, len(lines))):\n",
    "        parts = lines[i].split()\n",
    "        if len(parts) >= 3:\n",
    "            u, v, capacity = int(parts[0]), int(parts[1]), float(parts[2])\n",
    "            graph[(u, v)] = capacity\n",
    "    return graph, source, sink, n_nodes, n_edges\n",
    "\n",
    "\n",
    "def run_single_experiment(args):\n",
    "    graph, source, sink, seed, output_dir, filename_base, run = args\n",
    "    solver = MaxFlowTabuSearchOptimized(graph, source, sink)\n",
    "    result = solver.search(seed=seed)\n",
    "    plot_path = os.path.join(output_dir, f\"{filename_base}_run{run+1}_convergence.png\")\n",
    "    solver.plot_convergence(plot_path, title_suffix=f\"(Run {run+1})\")\n",
    "    print(f\"Run {run + 1}: Best={result['best_value']:.2f}, Iter={result['best_iteration']}, \"\n",
    "          f\"Eval={result['evaluations']}, Time={result['elapsed_time']:.4f}s\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_mean_convergence(runs_results, max_iterations):\n",
    "    common_iterations = np.linspace(0, max_iterations, 1000)\n",
    "    all_flows = []\n",
    "    \n",
    "    for run in runs_results:\n",
    "        interp_flow = np.interp(\n",
    "            common_iterations,\n",
    "            run['convergence_iterations'],\n",
    "            run['convergence_history'],\n",
    "            right=run['convergence_history'][-1]\n",
    "        )\n",
    "        all_flows.append(interp_flow)\n",
    "    \n",
    "    mean_flow = np.mean(all_flows, axis=0)\n",
    "    std_flow = np.std(all_flows, axis=0)\n",
    "    \n",
    "    return common_iterations, mean_flow, std_flow\n",
    "\n",
    "\n",
    "def get_best_run(runs_results):\n",
    "    scores = [r['best_value'] - (0.0001 * r['best_iteration']) for r in runs_results]\n",
    "    best_idx = np.argmax(scores)\n",
    "    return runs_results[best_idx]\n",
    "\n",
    "\n",
    "def run_experiments(output_dir=\"results\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    instance_files = [f for f in os.listdir() if f.startswith(\"network_\") and f.endswith(\".txt\")]\n",
    "    results = {}\n",
    "    \n",
    "    for filename in sorted(instance_files):\n",
    "        print(f\"\\n--- Processing instance: {filename} ---\")\n",
    "        try:\n",
    "            graph, source, sink, n_nodes, n_edges = read_instance(filename)\n",
    "            args_list = [(graph, source, sink, run + 42, output_dir, \n",
    "                         os.path.splitext(filename)[0], run) for run in range(10)]\n",
    "            \n",
    "            with Pool(max(1, cpu_count() // 2)) as p:\n",
    "                runs_results = p.map(run_single_experiment, args_list)\n",
    "\n",
    "            # Salva i dati grezzi\n",
    "            #raw_data_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_raw_data.json\")\n",
    "            #with open(raw_data_path, 'w') as f:\n",
    "            #    json.dump({\n",
    "            #        'runs': runs_results,\n",
    "            #        'optimal_flow': runs_results[0]['optimal_flow'],\n",
    "            #        'upper_bound': min(runs_results[0]['source_out_capacity'], \n",
    "            #                         runs_results[0]['sink_in_capacity'])\n",
    "            #    }, f)\n",
    "\n",
    "            # Calcola convergenza media corretta\n",
    "            max_iter = max([r['convergence_iterations'][-1] for r in runs_results])\n",
    "            x_vals, mean_conv, std_conv = compute_mean_convergence(runs_results, max_iter)\n",
    "\n",
    "            # Plot convergenza media\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(x_vals, mean_conv, label='Mean Flow', color='blue')\n",
    "            #plt.fill_between(x_vals, mean_conv - std_conv, mean_conv + std_conv, \n",
    "            #               alpha=0.2, color='blue', label='±1 Std Dev')\n",
    "            plt.axhline(y=runs_results[0]['optimal_flow'], color='red', \n",
    "                       linestyle='--', label='Optimal (Edmonds-Karp)')\n",
    "            #plt.axhline(y=min(runs_results[0]['source_out_capacity'], \n",
    "            #           runs_results[0]['sink_in_capacity']),\n",
    "            #           color='green', linestyle=':', label='Upper Bound')\n",
    "            plt.title(f'Mean Convergence for {filename}')\n",
    "            plt.xlabel('Iterations')\n",
    "            plt.ylabel('Flow Value')\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            mean_plot_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_mean_convergence.png\")\n",
    "            plt.savefig(mean_plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            # Plot miglior run (selezionata correttamente)\n",
    "            best_run = get_best_run(runs_results)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(best_run['convergence_iterations'], best_run['convergence_history'],\n",
    "                    label=f'Best Run (Flow={best_run[\"best_value\"]:.2f})', color='blue')\n",
    "            plt.axhline(y=best_run['optimal_flow'], color='red', \n",
    "                       linestyle='--', label='Optimal')\n",
    "            #plt.axhline(y=min(best_run['source_out_capacity'], best_run['sink_in_capacity']),\n",
    "            #           color='green', linestyle=':', label='Upper Bound')\n",
    "            plt.title(f'Best Run Convergence for {filename}\\n'\n",
    "                     f'Final Flow: {best_run[\"best_value\"]:.2f} | '\n",
    "                     f'Optimal: {best_run[\"optimal_flow\"]:.2f} | '\n",
    "                     f'Iter: {best_run[\"best_iteration\"]}')\n",
    "            plt.xlabel('Iterations')\n",
    "            plt.ylabel('Flow Value')\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            best_plot_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_best_convergence.png\")\n",
    "            plt.savefig(best_plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            # Statistiche finali\n",
    "            all_flows = [r['best_value'] for r in runs_results]\n",
    "            result = {\n",
    "                'best': max(all_flows),\n",
    "                'mean': np.mean(all_flows),\n",
    "                'std': np.std(all_flows),\n",
    "                'optimal': runs_results[0]['optimal_flow'],\n",
    "                'upper_bound': min(runs_results[0]['source_out_capacity'], \n",
    "                                 runs_results[0]['sink_in_capacity']),\n",
    "                'avg_iterations': np.mean([r['best_iteration'] for r in runs_results]),\n",
    "                'avg_evaluations': np.mean([r['evaluations'] for r in runs_results]),\n",
    "                'avg_time': np.mean([r['elapsed_time'] for r in runs_results])\n",
    "            }\n",
    "            results[filename] = result\n",
    "            \n",
    "            print(f\"\\nFinal statistics for {filename}:\")\n",
    "            print(f\"Best Flow (TS): {result['best']:.2f} (Optimal: {result['optimal']:.2f})\")\n",
    "            print(f\"Mean Flow (TS): {result['mean']:.2f} ± {result['std']:.2f}\")\n",
    "            print(f\"Upper Bound: {result['upper_bound']:.2f}\")\n",
    "            print(f\"Avg Iterations: {result['avg_iterations']:.0f}\")\n",
    "            print(f\"Avg Evaluations: {result['avg_evaluations']:.0f}\")\n",
    "            print(f\"Avg Time: {result['avg_time']:.4f}s\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    experiment_results = run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3471d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from google.colab import files\n",
    "\n",
    "def download_folder(folder_path):\n",
    "    # Crea un nome per il file zip\n",
    "    zip_name = f\"{os.path.basename(folder_path)}.zip\"\n",
    "\n",
    "    # Crea un archivio zip della cartella\n",
    "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files_list in os.walk(folder_path):\n",
    "            for file in files_list:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, start=folder_path)\n",
    "                zipf.write(file_path, arcname)\n",
    "\n",
    "    # Scarica il file zip (versione corretta)\n",
    "    from google.colab import files\n",
    "    files.download(zip_name)\n",
    "\n",
    "# Esempio di utilizzo:\n",
    "download_folder('/content/results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "class MaxFlowTabuSearchCombined:\n",
    "    def __init__(self, graph: Dict[Tuple[int, int], float], source: int, sink: int,\n",
    "                 tabu_tenure=20, max_iterations=20000):\n",
    "        self.source = source\n",
    "        self.sink = sink\n",
    "        self.graph = graph\n",
    "        self.edges = list(graph.keys())\n",
    "        self.capacities = np.array([graph[e] for e in self.edges], dtype=np.float32)\n",
    "        self.edge_to_idx = {(u, v): i for i, (u, v) in enumerate(self.edges)}\n",
    "        self.source_edges = [i for i, (u, v) in enumerate(self.edges) if u == self.source]\n",
    "        self.n_edges = len(self.edges)\n",
    "        self.tabu_tenure = tabu_tenure\n",
    "        self.max_iterations = max_iterations\n",
    "        self.current_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        self.best_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        self.best_value = 0.0\n",
    "        self.convergence_history = []\n",
    "        self.convergence_iterations = []\n",
    "        self.evaluations = 0\n",
    "        self.best_iteration = 0\n",
    "        self.start_time = time.time()\n",
    "        self._precompute_adjacency()\n",
    "        self.optimal_max_flow_value = self._run_edmonds_karp()\n",
    "        self.source_out_capacity = sum(cap for (u, v), cap in self.graph.items() if u == self.source)\n",
    "        self.sink_in_capacity = sum(cap for (u, v), cap in self.graph.items() if v == self.sink)\n",
    "        self._init_with_partial_edmonds_karp()\n",
    "\n",
    "    def _precompute_adjacency(self):\n",
    "        \"\"\"Build adjacency lists for faster navigation.\"\"\"\n",
    "        self.adj = defaultdict(list)\n",
    "        for (u, v) in self.graph:\n",
    "            self.adj[u].append(v)\n",
    "\n",
    "    def _run_edmonds_karp(self) -> float:\n",
    "        \"\"\"Edmonds-Karp implementation for optimal flow.\"\"\"\n",
    "        residual = defaultdict(float)\n",
    "        for (u, v), cap in self.graph.items():\n",
    "            residual[(u, v)] = cap\n",
    "            residual[(v, u)] = 0.0\n",
    "        flow = 0.0\n",
    "        while True:\n",
    "            parent = {}\n",
    "            visited = {self.source}\n",
    "            queue = deque([self.source])\n",
    "            found = False\n",
    "            while queue and not found:\n",
    "                u = queue.popleft()\n",
    "                for v in self.adj[u]:\n",
    "                    if residual[(u, v)] > 1e-6 and v not in visited:\n",
    "                        visited.add(v)\n",
    "                        parent[v] = u\n",
    "                        if v == self.sink:\n",
    "                            found = True\n",
    "                            break\n",
    "                        queue.append(v)\n",
    "            if not found:\n",
    "                break\n",
    "            path_flow = float('inf')\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                path_flow = min(path_flow, residual[(u, v)])\n",
    "                v = u\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                residual[(u, v)] -= path_flow\n",
    "                residual[(v, u)] += path_flow\n",
    "                v = u\n",
    "            flow += path_flow\n",
    "        return flow\n",
    "\n",
    "    def _init_with_partial_edmonds_karp(self):\n",
    "        \"\"\"Initialize with partial solution from Edmonds-Karp.\"\"\"\n",
    "        optimal_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        residual = defaultdict(float)\n",
    "        for idx, (u, v) in enumerate(self.edges):\n",
    "            residual[(u, v)] = self.capacities[idx]\n",
    "            residual[(v, u)] = 0.0\n",
    "        while True:\n",
    "            parent = {}\n",
    "            visited = {self.source}\n",
    "            queue = deque([self.source])\n",
    "            found = False\n",
    "            while queue and not found:\n",
    "                u = queue.popleft()\n",
    "                for v in self.adj[u]:\n",
    "                    if residual[(u, v)] > 1e-6 and v not in visited:\n",
    "                        visited.add(v)\n",
    "                        parent[v] = u\n",
    "                        if v == self.sink:\n",
    "                            found = True\n",
    "                            break\n",
    "                        queue.append(v)\n",
    "            if not found:\n",
    "                break\n",
    "            path_flow = float('inf')\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                path_flow = min(path_flow, residual[(u, v)])\n",
    "                v = u\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                edge = (u, v)\n",
    "                idx = self.edge_to_idx.get(edge, -1)\n",
    "                if idx >= 0:\n",
    "                    residual[(u, v)] -= path_flow\n",
    "                    residual[(v, u)] += path_flow\n",
    "                    optimal_flow[idx] += path_flow\n",
    "                v = u\n",
    "        factor = random.uniform(0.7, 0.95)\n",
    "        self.current_flow[:] = optimal_flow * factor\n",
    "        self.best_value = self._calculate_flow_value(self.current_flow)\n",
    "        self.best_flow[:] = self.current_flow\n",
    "        self.convergence_history = [self.best_value]\n",
    "        self.convergence_iterations = [0]\n",
    "\n",
    "    def _calculate_flow_value(self, flow):\n",
    "        self.evaluations += 1\n",
    "        return np.sum(flow[self.source_edges])\n",
    "\n",
    "    def _get_neighborhood_moves(self, current_flow, iteration):\n",
    "        moves = []\n",
    "        sample_size = min(len(self.edges), max(30, len(self.edges) // 80))  # Reduced sampling\n",
    "        sampled_edges = random.sample(range(len(self.edges)), sample_size)\n",
    "        for edge_idx in sampled_edges:\n",
    "            curr = current_flow[edge_idx]\n",
    "            cap = self.capacities[edge_idx]\n",
    "            if curr < cap - 1e-6:\n",
    "                step = min(cap - curr, cap * 0.2)\n",
    "                new_flow = current_flow.copy()\n",
    "                new_flow[edge_idx] += step\n",
    "                is_tabu = edge_idx in self.tabu_dict and self.tabu_dict[edge_idx] > iteration\n",
    "                moves.append((new_flow, edge_idx, step, is_tabu))\n",
    "            if curr > 1e-6:\n",
    "                step = min(curr, cap * 0.2)\n",
    "                new_flow = current_flow.copy()\n",
    "                new_flow[edge_idx] -= step\n",
    "                is_tabu = edge_idx in self.tabu_dict and self.tabu_dict[edge_idx] > iteration\n",
    "                moves.append((new_flow, edge_idx, -step, is_tabu))\n",
    "        return moves\n",
    "\n",
    "    def _diversify_solution(self, current_flow):\n",
    "        reset_factor = random.uniform(0.6, 0.8)\n",
    "        noise_factor = random.uniform(0.1, 0.2)\n",
    "        new_flow = current_flow * (1 - reset_factor)\n",
    "        num_perturb = min(len(self.edges) // 20, 5)\n",
    "        indices = random.sample(range(len(self.edges)), num_perturb)\n",
    "        for idx in indices:\n",
    "            cap = self.capacities[idx]\n",
    "            noise = random.uniform(-noise_factor, noise_factor) * cap\n",
    "            new_flow[idx] = max(0, min(cap, new_flow[idx] + noise))\n",
    "        return new_flow\n",
    "\n",
    "    def _adaptive_parameters(self, iteration, stagnation_counter):\n",
    "        if stagnation_counter > 100:\n",
    "            self.tabu_tenure = min(int(self.tabu_tenure * 1.2), 150)\n",
    "        elif stagnation_counter < 50:\n",
    "            self.tabu_tenure = max(int(self.tabu_tenure * 0.9), 10)\n",
    "        if iteration % 2000 == 0 and stagnation_counter > 300:\n",
    "            self.current_flow = self._diversify_solution(self.current_flow)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def plot_convergence(self, filename=None, title_suffix=\"\"):\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.plot(self.convergence_iterations, self.convergence_history, 'b-', label='Best Flow Value', linewidth=2)\n",
    "        plt.axhline(y=self.optimal_max_flow_value, color='r', linestyle='--',\n",
    "                   linewidth=1.5, label=f'Optimal (EK): {self.optimal_max_flow_value:.2f}')\n",
    "        plt.scatter([self.best_iteration], [self.best_value], color='g',\n",
    "                   s=100, zorder=5, label=f'Best: {self.best_value:.2f} at {self.best_iteration}')\n",
    "        plt.title(f'Tabu Search Convergence {title_suffix}\\n'\n",
    "                 f'Nodes: {len(set(n for n, _ in self.graph))}, Edges: {len(self.graph)}', pad=20)\n",
    "        plt.xlabel('Iterations', labelpad=10)\n",
    "        plt.ylabel('Flow Value', labelpad=10)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(loc='lower right')\n",
    "        info_text = (f\"Optimal: {self.optimal_max_flow_value:.2f}\\n\"\n",
    "                     f\"Evaluations: {self.evaluations}\\n\"\n",
    "                     f\"Time: {time.time() - self.start_time:.2f}s\")\n",
    "        plt.gcf().text(0.15, 0.7, info_text, bbox=dict(facecolor='white', alpha=0.8))\n",
    "        if filename:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def search(self, seed=None):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        self.tabu_dict = {}\n",
    "        stagnation_counter = 0\n",
    "        upper_bound = min(self.source_out_capacity, self.sink_in_capacity)\n",
    "        temp_flow = np.zeros_like(self.current_flow)\n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            diversified = self._adaptive_parameters(iteration, stagnation_counter)\n",
    "            if diversified:\n",
    "                stagnation_counter = 0\n",
    "\n",
    "            moves = self._get_neighborhood_moves(self.current_flow, iteration)\n",
    "            best_move = None\n",
    "            best_val = -np.inf\n",
    "\n",
    "            for move_flow, idx, delta, is_tabu in moves:\n",
    "                val = self._calculate_flow_value(move_flow)\n",
    "                if not is_tabu or val > self.best_value:\n",
    "                    if val > best_val:\n",
    "                        best_val = val\n",
    "                        best_move = (move_flow, idx)\n",
    "\n",
    "            if best_move is None:\n",
    "                stagnation_counter += 1\n",
    "                continue\n",
    "\n",
    "            new_flow, edge_idx = best_move\n",
    "            self.current_flow = new_flow\n",
    "\n",
    "            if isinstance(edge_idx, tuple):\n",
    "                for e in edge_idx:\n",
    "                    self.tabu_dict[e] = iteration + self.tabu_tenure\n",
    "            else:\n",
    "                self.tabu_dict[edge_idx] = iteration + self.tabu_tenure\n",
    "\n",
    "            # Update tabu list less frequently\n",
    "            if iteration % 500 == 0:\n",
    "                self.tabu_dict = {k: v for k, v in self.tabu_dict.items() if v > iteration}\n",
    "\n",
    "            current_val = self._calculate_flow_value(self.current_flow)\n",
    "\n",
    "            if current_val > self.best_value:\n",
    "                self.best_value = current_val\n",
    "                self.best_flow[:] = self.current_flow\n",
    "                self.best_iteration = iteration\n",
    "                stagnation_counter = 0\n",
    "            else:\n",
    "                stagnation_counter += 1\n",
    "\n",
    "            if iteration % 100 == 0 or current_val > self.convergence_history[-1] or iteration == self.max_iterations - 1:\n",
    "                self.convergence_history.append(current_val)\n",
    "                self.convergence_iterations.append(iteration)\n",
    "\n",
    "            # Early stopping based on theoretical bound\n",
    "            if abs(current_val - upper_bound) < 1e-6:\n",
    "                break\n",
    "\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        return {\n",
    "            'best_value': self.best_value,\n",
    "            'best_flow': self.best_flow.tolist(),\n",
    "            'best_iteration': self.best_iteration,\n",
    "            'evaluations': self.evaluations,\n",
    "            'elapsed_time': elapsed_time,\n",
    "            'convergence_history': self.convergence_history,\n",
    "            'convergence_iterations': self.convergence_iterations,\n",
    "            'optimal_flow': self.optimal_max_flow_value\n",
    "        }\n",
    "\n",
    "def read_instance(filename: str) -> Tuple[Dict[Tuple[int, int], float], int, int, int, int]:\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    n_nodes = int(lines[0])\n",
    "    n_edges = int(lines[1])\n",
    "    source = int(lines[2])\n",
    "    sink = int(lines[3])\n",
    "    graph = {}\n",
    "    for i in range(4, min(4 + n_edges, len(lines))):\n",
    "        parts = lines[i].split()\n",
    "        if len(parts) >= 3:\n",
    "            u, v, capacity = int(parts[0]), int(parts[1]), float(parts[2])\n",
    "            graph[(u, v)] = capacity\n",
    "    return graph, source, sink, n_nodes, n_edges\n",
    "\n",
    "def run_single_experiment(args):\n",
    "    graph, source, sink, seed, output_dir, filename_base, run = args\n",
    "    solver = MaxFlowTabuSearchCombined(graph, source, sink)\n",
    "    result = solver.search(seed=seed)\n",
    "    plot_path = os.path.join(output_dir, f\"{filename_base}_run{run+1}_convergence.png\")\n",
    "    solver.plot_convergence(plot_path, title_suffix=f\"(Run {run+1})\")\n",
    "    print(f\"Run {run + 1}: Best={result['best_value']:.2f}, Iter={result['best_iteration']}, \"\n",
    "          f\"Eval={result['evaluations']}, Time={result['elapsed_time']:.4f}s\")\n",
    "    return result\n",
    "\n",
    "def compute_mean_convergence(runs_results, max_iterations):\n",
    "    common_iterations = np.linspace(0, max_iterations, 1000)\n",
    "    all_flows = []\n",
    "    \n",
    "    for run in runs_results:\n",
    "        interp_flow = np.interp(\n",
    "            common_iterations,\n",
    "            run['convergence_iterations'],\n",
    "            run['convergence_history'],\n",
    "            right=run['convergence_history'][-1]\n",
    "        )\n",
    "        all_flows.append(interp_flow)\n",
    "    \n",
    "    mean_flow = np.mean(all_flows, axis=0)\n",
    "    std_flow = np.std(all_flows, axis=0)\n",
    "    \n",
    "    return common_iterations, mean_flow, std_flow\n",
    "\n",
    "\n",
    "def get_best_run(runs_results):\n",
    "    scores = [r['best_value'] - (0.0001 * r['best_iteration']) for r in runs_results]\n",
    "    best_idx = np.argmax(scores)\n",
    "    return runs_results[best_idx]\n",
    "\n",
    "def plot_average_convergence(results, filename, optimal_value):\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    max_iter = max(len(r['convergence_iterations']) for r in results)\n",
    "    x_vals, mean_conv, std_conv = compute_mean_convergence(results, max_iter)\n",
    "    plt.plot(x_vals, mean_conv, 'b-', linewidth=2, label='Average Flow')\n",
    "    plt.fill_between(x_vals, mean_conv - std_conv, mean_conv + std_conv, alpha=0.2)\n",
    "    plt.axhline(y=optimal_value, color='r', linestyle='--', linewidth=1.5, label=f'Optimal (EK): {optimal_value:.2f}')\n",
    "    plt.title(f'Average Convergence for {os.path.basename(filename)}\\n{len(results)} runs', pad=20)\n",
    "    plt.xlabel('Iterations', labelpad=10)\n",
    "    plt.ylabel('Flow Value', labelpad=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def run_experiments(output_dir=\"results\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    instance_files = [f for f in os.listdir() if f.startswith(\"network_\") and f.endswith(\".txt\")]\n",
    "    results = {}\n",
    "    for filename in sorted(instance_files):\n",
    "        print(f\"\\n--- Processing instance: {filename} ---\")\n",
    "        try:\n",
    "            graph, source, sink, n_nodes, n_edges = read_instance(filename)\n",
    "            args_list = [(graph, source, sink, run + 42, output_dir,\n",
    "                         os.path.splitext(os.path.basename(filename))[0], run) for run in range(10)]\n",
    "            with Pool(max(1, cpu_count() // 2)) as p:\n",
    "                runs_results = p.map(run_single_experiment, args_list)\n",
    "            #avg_plot_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_average_convergence.png\")\n",
    "            #plot_average_convergence(runs_results, avg_plot_path, runs_results[0]['optimal_flow'])\n",
    "            \n",
    "            # Calcola convergenza media corretta\n",
    "            max_iter = max([r['convergence_iterations'][-1] for r in runs_results])\n",
    "            x_vals, mean_conv, std_conv = compute_mean_convergence(runs_results, max_iter)\n",
    "\n",
    "            # Plot convergenza media\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(x_vals, mean_conv, label='Mean Flow', color='blue')\n",
    "            #plt.fill_between(x_vals, mean_conv - std_conv, mean_conv + std_conv, \n",
    "            #               alpha=0.2, color='blue', label='±1 Std Dev')\n",
    "            plt.axhline(y=runs_results[0]['optimal_flow'], color='red', \n",
    "                       linestyle='--', label='Optimal (Edmonds-Karp)')\n",
    "            #plt.axhline(y=min(runs_results[0]['source_out_capacity'], \n",
    "            #           runs_results[0]['sink_in_capacity']),\n",
    "            #           color='green', linestyle=':', label='Upper Bound')\n",
    "            plt.title(f'Mean Convergence for {filename}')\n",
    "            plt.xlabel('Iterations')\n",
    "            plt.ylabel('Flow Value')\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            mean_plot_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_mean_convergence.png\")\n",
    "            plt.savefig(mean_plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            # Plot miglior run (selezionata correttamente)\n",
    "            best_run = get_best_run(runs_results)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(best_run['convergence_iterations'], best_run['convergence_history'],\n",
    "                    label=f'Best Run (Flow={best_run[\"best_value\"]:.2f})', color='blue')\n",
    "            plt.axhline(y=best_run['optimal_flow'], color='red', \n",
    "                       linestyle='--', label='Optimal')\n",
    "            #plt.axhline(y=min(best_run['source_out_capacity'], best_run['sink_in_capacity']),\n",
    "            #           color='green', linestyle=':', label='Upper Bound')\n",
    "            plt.title(f'Best Run Convergence for {filename}\\n'\n",
    "                     f'Final Flow: {best_run[\"best_value\"]:.2f} | '\n",
    "                     f'Optimal: {best_run[\"optimal_flow\"]:.2f} | '\n",
    "                     f'Iter: {best_run[\"best_iteration\"]}')\n",
    "            plt.xlabel('Iterations')\n",
    "            plt.ylabel('Flow Value')\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            best_plot_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_best_convergence.png\")\n",
    "            plt.savefig(best_plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            all_flows = [r['best_value'] for r in runs_results]\n",
    "            result = {\n",
    "                'best': max(all_flows),\n",
    "                'mean': np.mean(all_flows),\n",
    "                'std': np.std(all_flows),\n",
    "                'avg_iterations': np.mean([r['best_iteration'] for r in runs_results]),\n",
    "                'avg_evaluations': np.mean([r['evaluations'] for r in runs_results]),\n",
    "                'avg_time': np.mean([r['elapsed_time'] for r in runs_results]),\n",
    "                'optimal_flow': runs_results[0]['optimal_flow']\n",
    "            }\n",
    "            results[filename] = result\n",
    "            print(f\"\\nFinal statistics for {filename}:\")\n",
    "            print(f\"Best Flow (TS): {result['best']:.2f} (Optimal: {result['optimal_flow']:.2f})\")\n",
    "            print(f\"Mean Flow (TS): {result['mean']:.2f} ± {result['std']:.2f}\")\n",
    "            print(f\"Avg Iterations: {result['avg_iterations']:.0f}\")\n",
    "            print(f\"Avg Evaluations: {result['avg_evaluations']:.0f}\")\n",
    "            print(f\"Avg Time: {result['avg_time']:.4f}s\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    experiment_results = run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b090581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Tuple, List, Optional, Literal\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "class MaxFlowTabuSearch:\n",
    "    def __init__(self, graph: Dict[Tuple[int, int], float], source: int, sink: int,\n",
    "                 tabu_tenure=20, max_iterations=20000,\n",
    "                 initialization: Literal['random', 'ek_partial', 'greedy'] = 'ek_partial'):\n",
    "        self.source = source\n",
    "        self.sink = sink\n",
    "        self.graph = graph\n",
    "        self.edges = list(graph.keys())\n",
    "        self.capacities = np.array([graph[e] for e in self.edges], dtype=np.float32)\n",
    "        self.edge_to_idx = {(u, v): i for i, (u, v) in enumerate(self.edges)}\n",
    "        self.source_edges = [i for i, (u, v) in enumerate(self.edges) if u == self.source]\n",
    "        self.n_edges = len(self.edges)\n",
    "        self.tabu_tenure = tabu_tenure\n",
    "        self.max_iterations = max_iterations\n",
    "        self.initialization = initialization\n",
    "        self.current_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        self.best_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        self.best_value = 0.0\n",
    "        self.convergence_history = []\n",
    "        self.convergence_iterations = []\n",
    "        self.evaluations = 0\n",
    "        self.best_iteration = 0\n",
    "        self.start_time = time.time()\n",
    "        self._precompute_adjacency()\n",
    "        self.optimal_max_flow_value = self._run_edmonds_karp()\n",
    "        self.source_out_capacity = sum(cap for (u, v), cap in self.graph.items() if u == self.source)\n",
    "        self.sink_in_capacity = sum(cap for (u, v), cap in self.graph.items() if v == self.sink)\n",
    "        self._initialize_flow()\n",
    "        self.tabu_dict = {}\n",
    "\n",
    "    def _precompute_adjacency(self):\n",
    "        self.adj = defaultdict(list)\n",
    "        for (u, v) in self.graph:\n",
    "            self.adj[u].append(v)\n",
    "\n",
    "    def _run_edmonds_karp(self) -> float:\n",
    "        residual = defaultdict(float)\n",
    "        for (u, v), cap in self.graph.items():\n",
    "            residual[(u, v)] = cap\n",
    "            residual[(v, u)] = 0.0\n",
    "        flow = 0.0\n",
    "        while True:\n",
    "            parent = {}\n",
    "            visited = {self.source}\n",
    "            queue = deque([self.source])\n",
    "            found = False\n",
    "            while queue and not found:\n",
    "                u = queue.popleft()\n",
    "                for v in self.adj[u]:\n",
    "                    if residual[(u, v)] > 1e-6 and v not in visited:\n",
    "                        visited.add(v)\n",
    "                        parent[v] = u\n",
    "                        if v == self.sink:\n",
    "                            found = True\n",
    "                            break\n",
    "                        queue.append(v)\n",
    "            if not found:\n",
    "                break\n",
    "            path_flow = float('inf')\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                path_flow = min(path_flow, residual[(u, v)])\n",
    "                v = u\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                residual[(u, v)] -= path_flow\n",
    "                residual[(v, u)] += path_flow\n",
    "                v = u\n",
    "            flow += path_flow\n",
    "        return flow\n",
    "\n",
    "    def _initialize_flow(self):\n",
    "        if self.initialization == 'random':\n",
    "            self._random_initialization()\n",
    "        elif self.initialization == 'ek_partial':\n",
    "            self._ek_partial_initialization()\n",
    "        elif self.initialization == 'ek_full':\n",
    "            self._ek_full_initialization()\n",
    "        elif self.initialization == 'greedy':\n",
    "            self._greedy_initialization()\n",
    "        \n",
    "        self.best_value = self._calculate_flow_value(self.current_flow)\n",
    "        self.best_flow = self.current_flow.copy()\n",
    "        self.convergence_history = [self.best_value]\n",
    "        self.convergence_iterations = [0]\n",
    "\n",
    "    def _random_initialization(self):\n",
    "        \"\"\"Initialize with random flows respecting capacities\"\"\"\n",
    "        self.current_flow = np.array([random.uniform(0, cap) for cap in self.capacities], dtype=np.float32)\n",
    "        \n",
    "    def _ek_partial_initialization(self):\n",
    "        \"\"\"Initialize with a fraction (70-95%) of the Edmonds-Karp solution\"\"\"\n",
    "        optimal_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        residual = defaultdict(float)\n",
    "        for idx, (u, v) in enumerate(self.edges):\n",
    "            residual[(u, v)] = self.capacities[idx]\n",
    "            residual[(v, u)] = 0.0\n",
    "        \n",
    "        while True:\n",
    "            parent = {}\n",
    "            visited = {self.source}\n",
    "            queue = deque([self.source])\n",
    "            found = False\n",
    "            while queue and not found:\n",
    "                u = queue.popleft()\n",
    "                for v in self.adj[u]:\n",
    "                    if residual[(u, v)] > 1e-6 and v not in visited:\n",
    "                        visited.add(v)\n",
    "                        parent[v] = u\n",
    "                        if v == self.sink:\n",
    "                            found = True\n",
    "                            break\n",
    "                        queue.append(v)\n",
    "            if not found:\n",
    "                break\n",
    "            path_flow = float('inf')\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                path_flow = min(path_flow, residual[(u, v)])\n",
    "                v = u\n",
    "            v = self.sink\n",
    "            while v != self.source:\n",
    "                u = parent[v]\n",
    "                residual[(u, v)] -= path_flow\n",
    "                residual[(v, u)] += path_flow\n",
    "                optimal_flow[self.edge_to_idx[(u, v)]] += path_flow\n",
    "                v = u\n",
    "        \n",
    "        factor = random.uniform(0.7, 0.95)\n",
    "        self.current_flow = optimal_flow * factor\n",
    "                 \n",
    "    def _greedy_initialization(self):\n",
    "        \"\"\"Initialize by greedily pushing flow from source to sink along paths with max residual capacity\"\"\"\n",
    "        self.current_flow = np.zeros(len(self.edges), dtype=np.float32)\n",
    "        residual = self.capacities.copy()\n",
    "        \n",
    "        for _ in range(10):  # Perform a limited number of greedy pushes\n",
    "            path = self._find_augmenting_path_greedy(residual)\n",
    "            if not path:\n",
    "                break\n",
    "            min_residual = min(residual[edge_idx] for edge_idx in path)\n",
    "            for edge_idx in path:\n",
    "                self.current_flow[edge_idx] += min_residual\n",
    "                residual[edge_idx] -= min_residual\n",
    "\n",
    "    def _find_augmenting_path_greedy(self, residual):\n",
    "        \"\"\"Find a path with maximum residual capacity using modified Dijkstra's algorithm\"\"\"\n",
    "        parent = {}\n",
    "        capacity = {}\n",
    "        visited = set()\n",
    "        queue = [self.source]\n",
    "        visited.add(self.source)\n",
    "        capacity[self.source] = float('inf')\n",
    "        \n",
    "        while queue:\n",
    "            u = max(queue, key=lambda x: capacity[x])\n",
    "            queue.remove(u)\n",
    "            \n",
    "            for v in self.adj[u]:\n",
    "                edge_idx = self.edge_to_idx[(u, v)]\n",
    "                if residual[edge_idx] > 1e-6 and v not in visited:\n",
    "                    visited.add(v)\n",
    "                    parent[v] = u\n",
    "                    capacity[v] = min(capacity[u], residual[edge_idx])\n",
    "                    if v == self.sink:\n",
    "                        path = []\n",
    "                        node = self.sink\n",
    "                        while node != self.source:\n",
    "                            edge_idx = self.edge_to_idx[(parent[node], node)]\n",
    "                            path.append(edge_idx)\n",
    "                            node = parent[node]\n",
    "                        return path[::-1]\n",
    "                    queue.append(v)\n",
    "        return None\n",
    "\n",
    "    def _calculate_flow_value(self, flow):\n",
    "        self.evaluations += 1\n",
    "        return np.sum(flow[self.source_edges])\n",
    "\n",
    "    def _find_augmenting_path(self, flow):\n",
    "        parent = {}\n",
    "        visited = set()\n",
    "        queue = deque([self.source])\n",
    "        visited.add(self.source)\n",
    "        found = False\n",
    "        while queue and not found:\n",
    "            u = queue.popleft()\n",
    "            for v in self.adj[u]:\n",
    "                residual = self.graph[(u, v)] - flow[self.edge_to_idx[(u, v)]]\n",
    "                if residual > 1e-6 and v not in visited:\n",
    "                    visited.add(v)\n",
    "                    parent[v] = u\n",
    "                    if v == self.sink:\n",
    "                        found = True\n",
    "                        break\n",
    "                    queue.append(v)\n",
    "        if not found:\n",
    "            return None\n",
    "        path = []\n",
    "        v = self.sink\n",
    "        while v != self.source:\n",
    "            u = parent[v]\n",
    "            path.append((self.edge_to_idx[(u, v)], True))\n",
    "            v = u\n",
    "        return path[::-1]\n",
    "\n",
    "    def _generate_edge_exchange_moves(self, current_flow, n_exchanges=5):\n",
    "        moves = []\n",
    "        saturated = [i for i in range(self.n_edges) \n",
    "                    if current_flow[i] >= self.capacities[i] - 1e-6]\n",
    "        unsaturated = [i for i in range(self.n_edges) \n",
    "                      if current_flow[i] < self.capacities[i] - 1e-6]\n",
    "        for _ in range(min(n_exchanges, len(saturated), len(unsaturated))):\n",
    "            src, dest = random.choice(saturated), random.choice(unsaturated)\n",
    "            delta = min(current_flow[src], self.capacities[dest] - current_flow[dest])\n",
    "            if delta > 1e-6:\n",
    "                new_flow = current_flow.copy()\n",
    "                new_flow[src] -= delta\n",
    "                new_flow[dest] += delta\n",
    "                moves.append((new_flow, (src, dest), delta, False))\n",
    "        return moves\n",
    "\n",
    "    def _get_neighborhood_moves(self, current_flow, iteration):\n",
    "        moves = []\n",
    "        # Basic moves (increment/decrement)\n",
    "        sample_size = min(30, self.n_edges // 80)\n",
    "        for edge_idx in random.sample(range(self.n_edges), sample_size):\n",
    "            curr = current_flow[edge_idx]\n",
    "            cap = self.capacities[edge_idx]\n",
    "            if curr < cap - 1e-6:\n",
    "                step = min(cap - curr, cap * 0.2)\n",
    "                new_flow = current_flow.copy()\n",
    "                new_flow[edge_idx] += step\n",
    "                is_tabu = edge_idx in self.tabu_dict and self.tabu_dict[edge_idx] > iteration\n",
    "                moves.append((new_flow, edge_idx, step, is_tabu))\n",
    "            if curr > 1e-6:\n",
    "                step = min(curr, cap * 0.2)\n",
    "                new_flow = current_flow.copy()\n",
    "                new_flow[edge_idx] -= step\n",
    "                is_tabu = edge_idx in self.tabu_dict and self.tabu_dict[edge_idx] > iteration\n",
    "                moves.append((new_flow, edge_idx, -step, is_tabu))\n",
    "        \n",
    "        # Edge exchange (every 20 iterations)\n",
    "        if iteration % 20 == 0:\n",
    "            moves.extend(self._generate_edge_exchange_moves(current_flow))\n",
    "        \n",
    "        # Path augmentation (every 100 iterations or if stagnating)\n",
    "        if iteration % 100 == 0:\n",
    "            path = self._find_augmenting_path(current_flow)\n",
    "            if path:\n",
    "                min_residual = min(\n",
    "                    self.capacities[edge_idx] - current_flow[edge_idx] if is_forward \n",
    "                    else current_flow[edge_idx]\n",
    "                    for edge_idx, is_forward in path\n",
    "                )\n",
    "                if min_residual > 1e-6:\n",
    "                    new_flow = current_flow.copy()\n",
    "                    for edge_idx, is_forward in path:\n",
    "                        if is_forward:\n",
    "                            new_flow[edge_idx] += min_residual\n",
    "                        else:\n",
    "                            new_flow[edge_idx] -= min_residual\n",
    "                    moves.append((new_flow, tuple(edge_idx for edge_idx, _ in path), min_residual, False))\n",
    "        return moves\n",
    "\n",
    "    def _diversify_solution(self, current_flow):\n",
    "        reset_factor = random.uniform(0.6, 0.8)\n",
    "        noise_factor = random.uniform(0.1, 0.2)\n",
    "        new_flow = current_flow * (1 - reset_factor)\n",
    "        num_perturb = min(len(self.edges) // 20, 5)\n",
    "        indices = random.sample(range(len(self.edges)), num_perturb)\n",
    "        for idx in indices:\n",
    "            cap = self.capacities[idx]\n",
    "            noise = random.uniform(-noise_factor, noise_factor) * cap\n",
    "            new_flow[idx] = max(0, min(cap, new_flow[idx] + noise))\n",
    "        return new_flow\n",
    "\n",
    "    def _adaptive_parameters(self, iteration, stagnation_counter):\n",
    "        if stagnation_counter > 100:\n",
    "            self.tabu_tenure = min(int(self.tabu_tenure * 1.2), 150)\n",
    "        elif stagnation_counter < 50:\n",
    "            self.tabu_tenure = max(int(self.tabu_tenure * 0.9), 10)\n",
    "        if iteration % 2000 == 0 and stagnation_counter > 300:\n",
    "            self.current_flow = self._diversify_solution(self.current_flow)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def plot_convergence(self, filename=None, title_suffix=\"\"):\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.plot(self.convergence_iterations, self.convergence_history, 'b-', label='Best Flow Value', linewidth=2)\n",
    "        plt.axhline(y=self.optimal_max_flow_value, color='r', linestyle='--',\n",
    "                   linewidth=1.5, label=f'Optimal (EK): {self.optimal_max_flow_value:.2f}')\n",
    "        plt.scatter([self.best_iteration], [self.best_value], color='g',\n",
    "                   s=100, zorder=5, label=f'Best: {self.best_value:.2f} at {self.best_iteration}')\n",
    "        plt.title(f'Tabu Search Convergence {title_suffix}\\n'\n",
    "                 f'Nodes: {len(set(n for n, _ in self.graph))}, Edges: {len(self.graph)}', pad=20)\n",
    "        plt.xlabel('Iterations', labelpad=10)\n",
    "        plt.ylabel('Flow Value', labelpad=10)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(loc='lower right')\n",
    "        info_text = (f\"Optimal: {self.optimal_max_flow_value:.2f}\\n\"\n",
    "                     f\"Evaluations: {self.evaluations}\\n\"\n",
    "                     f\"Time: {time.time() - self.start_time:.2f}s\")\n",
    "        plt.gcf().text(0.15, 0.7, info_text, bbox=dict(facecolor='white', alpha=0.8))\n",
    "        if filename:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def search(self, seed=None):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        self.tabu_dict = {}\n",
    "        stagnation_counter = 0\n",
    "        upper_bound = min(self.source_out_capacity, self.sink_in_capacity)\n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            diversified = self._adaptive_parameters(iteration, stagnation_counter)\n",
    "            if diversified:\n",
    "                stagnation_counter = 0\n",
    "\n",
    "            moves = self._get_neighborhood_moves(self.current_flow, iteration)\n",
    "            best_move = None\n",
    "            best_val = -np.inf\n",
    "\n",
    "            for move_flow, idx, delta, is_tabu in moves:\n",
    "                if not is_tabu or self._calculate_flow_value(move_flow) > self.best_value:\n",
    "                    val = self._calculate_flow_value(move_flow)\n",
    "                    if val > best_val:\n",
    "                        best_val = val\n",
    "                        best_move = (move_flow, idx)\n",
    "\n",
    "            if best_move is None:\n",
    "                stagnation_counter += 1\n",
    "                continue\n",
    "\n",
    "            new_flow, edge_idx = best_move\n",
    "            self.current_flow = new_flow\n",
    "\n",
    "            if isinstance(edge_idx, tuple):\n",
    "                for e in edge_idx:\n",
    "                    self.tabu_dict[e] = iteration + self.tabu_tenure\n",
    "            else:\n",
    "                self.tabu_dict[edge_idx] = iteration + self.tabu_tenure\n",
    "\n",
    "            if iteration % 500 == 0:\n",
    "                self.tabu_dict = {k: v for k, v in self.tabu_dict.items() if v > iteration}\n",
    "\n",
    "            current_val = self._calculate_flow_value(self.current_flow)\n",
    "\n",
    "            if current_val > self.best_value:\n",
    "                self.best_value = current_val\n",
    "                self.best_flow = self.current_flow.copy()\n",
    "                self.best_iteration = iteration\n",
    "                stagnation_counter = 0\n",
    "            else:\n",
    "                stagnation_counter += 1\n",
    "\n",
    "            if iteration % 100 == 0 or current_val > self.convergence_history[-1]:\n",
    "                self.convergence_history.append(self.best_value)\n",
    "                self.convergence_iterations.append(iteration)\n",
    "\n",
    "            if abs(current_val - upper_bound) < 1e-6:\n",
    "                break\n",
    "\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        return {\n",
    "            'best_value': self.best_value,\n",
    "            'best_flow': self.best_flow.tolist(),\n",
    "            'best_iteration': self.best_iteration,\n",
    "            'evaluations': self.evaluations,\n",
    "            'elapsed_time': elapsed_time,\n",
    "            'convergence_history': self.convergence_history,\n",
    "            'convergence_iterations': self.convergence_iterations,\n",
    "            'optimal_flow': self.optimal_max_flow_value\n",
    "        }\n",
    "\n",
    "# Resto del codice (read_instance, run_single_experiment, compute_mean_convergence, ...) rimane identico\n",
    "def read_instance(filename: str) -> Tuple[Dict[Tuple[int, int], float], int, int, int, int]:\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    n_nodes = int(lines[0])\n",
    "    n_edges = int(lines[1])\n",
    "    source = int(lines[2])\n",
    "    sink = int(lines[3])\n",
    "    graph = {}\n",
    "    for i in range(4, min(4 + n_edges, len(lines))):\n",
    "        parts = lines[i].split()\n",
    "        if len(parts) >= 3:\n",
    "            u, v, capacity = int(parts[0]), int(parts[1]), float(parts[2])\n",
    "            graph[(u, v)] = capacity\n",
    "    return graph, source, sink, n_nodes, n_edges\n",
    "\n",
    "def run_single_experiment(args):\n",
    "    graph, source, sink, seed, output_dir, filename_base, run = args\n",
    "    solver = MaxFlowTabuSearch(graph, source, sink, initialization=\"random\")\n",
    "    result = solver.search(seed=seed)\n",
    "    plot_path = os.path.join(output_dir, f\"{filename_base}_run{run+1}_convergence.png\")\n",
    "    solver.plot_convergence(plot_path, title_suffix=f\"(Run {run+1})\")\n",
    "    print(f\"Run {run + 1}: Best={result['best_value']:.2f}, Iter={result['best_iteration']}, \"\n",
    "          f\"Eval={result['evaluations']}, Time={result['elapsed_time']:.4f}s\")\n",
    "    return result\n",
    "\n",
    "def compute_mean_convergence(runs_results, max_iterations):\n",
    "    common_iterations = np.linspace(0, max_iterations, 1000)\n",
    "    all_flows = []\n",
    "\n",
    "    for run in runs_results:\n",
    "        interp_flow = np.interp(\n",
    "            common_iterations,\n",
    "            run['convergence_iterations'],\n",
    "            run['convergence_history'],\n",
    "            right=run['convergence_history'][-1]\n",
    "        )\n",
    "        all_flows.append(interp_flow)\n",
    "\n",
    "    mean_flow = np.mean(all_flows, axis=0)\n",
    "    std_flow = np.std(all_flows, axis=0)\n",
    "\n",
    "    return common_iterations, mean_flow, std_flow\n",
    "\n",
    "\n",
    "def get_best_run(runs_results):\n",
    "    scores = [r['best_value'] - (0.0001 * r['best_iteration']) for r in runs_results]\n",
    "    best_idx = np.argmax(scores)\n",
    "    return runs_results[best_idx]\n",
    "\n",
    "def plot_average_convergence(results, filename, optimal_value):\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    max_iter = max(len(r['convergence_iterations']) for r in results)\n",
    "    x_vals, mean_conv, std_conv = compute_mean_convergence(results, max_iter)\n",
    "    plt.plot(x_vals, mean_conv, 'b-', linewidth=2, label='Average Flow')\n",
    "    plt.fill_between(x_vals, mean_conv - std_conv, mean_conv + std_conv, alpha=0.2)\n",
    "    plt.axhline(y=optimal_value, color='r', linestyle='--', linewidth=1.5, label=f'Optimal (EK): {optimal_value:.2f}')\n",
    "    plt.title(f'Average Convergence for {os.path.basename(filename)}\\n{len(results)} runs', pad=20)\n",
    "    plt.xlabel('Iterations', labelpad=10)\n",
    "    plt.ylabel('Flow Value', labelpad=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def run_experiments(output_dir=\"results\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    instance_files = [f for f in os.listdir() if f.startswith(\"network_\") and f.endswith(\".txt\")]\n",
    "    results = {}\n",
    "    for filename in sorted(instance_files):\n",
    "        print(f\"\\n--- Processing instance: {filename} ---\")\n",
    "        try:\n",
    "            graph, source, sink, n_nodes, n_edges = read_instance(filename)\n",
    "            args_list = [(graph, source, sink, run + 42, output_dir,\n",
    "                         os.path.splitext(os.path.basename(filename))[0], run) for run in range(10)]\n",
    "            with Pool(max(1, cpu_count() // 2)) as p:\n",
    "                runs_results = p.map(run_single_experiment, args_list)\n",
    "            #avg_plot_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_average_convergence.png\")\n",
    "            #plot_average_convergence(runs_results, avg_plot_path, runs_results[0]['optimal_flow'])\n",
    "\n",
    "            # Calcola convergenza media corretta\n",
    "            max_iter = max([r['convergence_iterations'][-1] for r in runs_results])\n",
    "            x_vals, mean_conv, std_conv = compute_mean_convergence(runs_results, max_iter)\n",
    "\n",
    "            # Plot convergenza media\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(x_vals, mean_conv, label='Mean Flow', color='blue')\n",
    "            #plt.fill_between(x_vals, mean_conv - std_conv, mean_conv + std_conv,\n",
    "            #               alpha=0.2, color='blue', label='±1 Std Dev')\n",
    "            plt.axhline(y=runs_results[0]['optimal_flow'], color='red',\n",
    "                       linestyle='--', label='Optimal (Edmonds-Karp)')\n",
    "            #plt.axhline(y=min(runs_results[0]['source_out_capacity'],\n",
    "            #           runs_results[0]['sink_in_capacity']),\n",
    "            #           color='green', linestyle=':', label='Upper Bound')\n",
    "            plt.title(f'Mean Convergence for {filename}')\n",
    "            plt.xlabel('Iterations')\n",
    "            plt.ylabel('Flow Value')\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            mean_plot_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_mean_convergence.png\")\n",
    "            plt.savefig(mean_plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            # Plot miglior run (selezionata correttamente)\n",
    "            best_run = get_best_run(runs_results)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(best_run['convergence_iterations'], best_run['convergence_history'],\n",
    "                    label=f'Best Run (Flow={best_run[\"best_value\"]:.2f})', color='blue')\n",
    "            plt.axhline(y=best_run['optimal_flow'], color='red',\n",
    "                       linestyle='--', label='Optimal')\n",
    "            #plt.axhline(y=min(best_run['source_out_capacity'], best_run['sink_in_capacity']),\n",
    "            #           color='green', linestyle=':', label='Upper Bound')\n",
    "            plt.title(f'Best Run Convergence for {filename}\\n'\n",
    "                     f'Final Flow: {best_run[\"best_value\"]:.2f} | '\n",
    "                     f'Optimal: {best_run[\"optimal_flow\"]:.2f} | '\n",
    "                     f'Iter: {best_run[\"best_iteration\"]}')\n",
    "            plt.xlabel('Iterations')\n",
    "            plt.ylabel('Flow Value')\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            best_plot_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_best_convergence.png\")\n",
    "            plt.savefig(best_plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            all_flows = [r['best_value'] for r in runs_results]\n",
    "            result = {\n",
    "                'best': max(all_flows),\n",
    "                'mean': np.mean(all_flows),\n",
    "                'std': np.std(all_flows),\n",
    "                'avg_iterations': np.mean([r['best_iteration'] for r in runs_results]),\n",
    "                'avg_evaluations': np.mean([r['evaluations'] for r in runs_results]),\n",
    "                'avg_time': np.mean([r['elapsed_time'] for r in runs_results]),\n",
    "                'optimal_flow': runs_results[0]['optimal_flow']\n",
    "            }\n",
    "            results[filename] = result\n",
    "            print(f\"\\nFinal statistics for {filename}:\")\n",
    "            print(f\"Best Flow (TS): {result['best']:.2f} (Optimal: {result['optimal_flow']:.2f})\")\n",
    "            print(f\"Mean Flow (TS): {result['mean']:.2f} ± {result['std']:.2f}\")\n",
    "            print(f\"Avg Iterations: {result['avg_iterations']:.0f}\")\n",
    "            print(f\"Avg Evaluations: {result['avg_evaluations']:.0f}\")\n",
    "            print(f\"Avg Time: {result['avg_time']:.4f}s\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "    return results\n",
    "                       \n",
    "if __name__ == \"__main__\":\n",
    "    experiment_results = run_experiments()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
